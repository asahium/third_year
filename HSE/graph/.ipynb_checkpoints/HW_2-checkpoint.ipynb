{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "understanding-software",
   "metadata": {
    "id": "understanding-software"
   },
   "source": [
    "# Домашнее задание 2 \n",
    "\n",
    "## Глубинное обучение в анализе графовых данных, ПМИ ВШЭ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-freeze",
   "metadata": {
    "id": "declared-freeze"
   },
   "source": [
    "В этом дз для мониторинга экспериментов лучше использовать сервис __wandb__, [здесь](https://docs.wandb.ai/quickstart) можете ознакомиться с документацией"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-fisher",
   "metadata": {
    "id": "certain-fisher"
   },
   "source": [
    "### 1. PageRank Personalized (1 балл)\n",
    "\n",
    "Реализуйте на основе кода с семинара персонализованный алгоритм PageRank с опцией возвращения в одну точку (индекс который подается в keep_updating_until_convergence(...)), либо же topic-related с возможностью вернуться в определенный массив точек (подается в эту же функцию). Подумайте над реализацией, опишите как вы решили модифицирвоать алгоритм, продемонстрируйте работспособность на каком-нибудь искуственном наборе данных (можно двудольном). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-onion",
   "metadata": {
    "id": "headed-onion"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-carnival",
   "metadata": {
    "id": "enclosed-carnival"
   },
   "source": [
    "### Реализация слоев графовых нейронных сетей для классификации вершин"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-newman",
   "metadata": {
    "id": "lined-newman"
   },
   "source": [
    "На 5ом семинаре мы реализовали слой **GraphSAGE** ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)). Здесь вы должны реализовать еще более мощные слои: **GAT** ([Veličković et al. (2018)](https://arxiv.org/abs/1710.10903)) и **GCN** ([Kipf et al. (2017)](https://arxiv.org/abs/1609.02907)). Затем вы должны запустить модели для решения задачи классификации вершин на наборе данных CORA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "placed-fleet",
   "metadata": {
    "id": "placed-fleet"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
      "Collecting torch-scatter\n",
      "  Using cached torch_scatter-2.1.2.tar.gz (108 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: torch-scatter\n",
      "  Building wheel for torch-scatter (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[38 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/utils.py -> build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/testing.py -> build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/segment_csr.py -> build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/segment_coo.py -> build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/scatter.py -> build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/placeholder.py -> build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/__init__.py -> build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/std.py -> build/lib.linux-x86_64-cpython-311/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/softmax.py -> build/lib.linux-x86_64-cpython-311/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/logsumexp.py -> build/lib.linux-x86_64-cpython-311/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/__init__.py -> build/lib.linux-x86_64-cpython-311/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing torch_scatter.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to torch_scatter.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to torch_scatter.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to torch_scatter.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'torch_scatter._version_cpu' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311/csrc\n",
      "  \u001b[31m   \u001b[0m gcc -Wsign-compare -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -fcf-protection -fexceptions -fcf-protection -fexceptions -fcf-protection -fexceptions -fPIC -DWITH_PYTHON -Icsrc -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/TH -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/THC -I/usr/include/python3.11 -c csrc/version.cpp -o build/temp.linux-x86_64-cpython-311/csrc/version.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_version_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m csrc/version.cpp:2:10: fatal error: Python.h: No such file or directory\n",
      "  \u001b[31m   \u001b[0m     2 | #include <Python.h>\n",
      "  \u001b[31m   \u001b[0m       |          ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m error: command '/bin/gcc' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for torch-scatter\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for torch-scatter\n",
      "Failed to build torch-scatter\n",
      "\u001b[31mERROR: Could not build wheels for torch-scatter, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
      "Collecting torch-sparse\n",
      "  Using cached torch_sparse-0.6.18.tar.gz (209 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib64/python3.11/site-packages (from torch-sparse) (1.10.0)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib64/python3.11/site-packages (from scipy->torch-sparse) (1.24.1)\n",
      "Building wheels for collected packages: torch-sparse\n",
      "  Building wheel for torch-sparse (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[132 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/utils.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/typing.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/transpose.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/testing.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/tensor.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/storage.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spspmm.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spmm.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spadd.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/select.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/sample.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/saint.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/rw.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/reduce.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/permute.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/narrow.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/mul.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/metis.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/matmul.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/masked_select.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/index_select.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/eye.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/diag.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/convert.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/coalesce.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/cat.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/bandwidth.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/add.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/__init__.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing torch_sparse.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to torch_sparse.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to torch_sparse.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to torch_sparse.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/css'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/html'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/tests'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/examples'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/benchmark'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'benchmark'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'torch_sparse._version_cpu' extension\n",
      "  \u001b[31m   \u001b[0m creating /tmp/pip-install-m4mhmm0l/torch-sparse_647f184f813646caabbdb103ca8f7c19/build/temp.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating /tmp/pip-install-m4mhmm0l/torch-sparse_647f184f813646caabbdb103ca8f7c19/build/temp.linux-x86_64-cpython-311/csrc\n",
      "  \u001b[31m   \u001b[0m Emitting ninja build file /tmp/pip-install-m4mhmm0l/torch-sparse_647f184f813646caabbdb103ca8f7c19/build/temp.linux-x86_64-cpython-311/build.ninja...\n",
      "  \u001b[31m   \u001b[0m Compiling objects...\n",
      "  \u001b[31m   \u001b[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  \u001b[31m   \u001b[0m [1/1] c++ -MMD -MF /tmp/pip-install-m4mhmm0l/torch-sparse_647f184f813646caabbdb103ca8f7c19/build/temp.linux-x86_64-cpython-311/csrc/version.o.d -Wsign-compare -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -fcf-protection -fexceptions -fcf-protection -fexceptions -fcf-protection -fexceptions -fPIC -DWITH_PYTHON -Icsrc -I/tmp/pip-install-m4mhmm0l/torch-sparse_647f184f813646caabbdb103ca8f7c19/third_party/parallel-hashmap -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/TH -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/THC -I/usr/include/python3.11 -c -c /tmp/pip-install-m4mhmm0l/torch-sparse_647f184f813646caabbdb103ca8f7c19/csrc/version.cpp -o /tmp/pip-install-m4mhmm0l/torch-sparse_647f184f813646caabbdb103ca8f7c19/build/temp.linux-x86_64-cpython-311/csrc/version.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_version_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m \u001b[31mFAILED: \u001b[0m/tmp/pip-install-m4mhmm0l/torch-sparse_647f184f813646caabbdb103ca8f7c19/build/temp.linux-x86_64-cpython-311/csrc/version.o\n",
      "  \u001b[31m   \u001b[0m c++ -MMD -MF /tmp/pip-install-m4mhmm0l/torch-sparse_647f184f813646caabbdb103ca8f7c19/build/temp.linux-x86_64-cpython-311/csrc/version.o.d -Wsign-compare -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -fcf-protection -fexceptions -fcf-protection -fexceptions -fcf-protection -fexceptions -fPIC -DWITH_PYTHON -Icsrc -I/tmp/pip-install-m4mhmm0l/torch-sparse_647f184f813646caabbdb103ca8f7c19/third_party/parallel-hashmap -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/TH -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/THC -I/usr/include/python3.11 -c -c /tmp/pip-install-m4mhmm0l/torch-sparse_647f184f813646caabbdb103ca8f7c19/csrc/version.cpp -o /tmp/pip-install-m4mhmm0l/torch-sparse_647f184f813646caabbdb103ca8f7c19/build/temp.linux-x86_64-cpython-311/csrc/version.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_version_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-install-m4mhmm0l/torch-sparse_647f184f813646caabbdb103ca8f7c19/csrc/version.cpp:2:10: fatal error: Python.h: No such file or directory\n",
      "  \u001b[31m   \u001b[0m     2 | #include <Python.h>\n",
      "  \u001b[31m   \u001b[0m       |          ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m ninja: build stopped: subcommand failed.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 2100, in _run_ninja_build\n",
      "  \u001b[31m   \u001b[0m     subprocess.run(\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib64/python3.11/subprocess.py\", line 571, in run\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, process.args,\n",
      "  \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-m4mhmm0l/torch-sparse_647f184f813646caabbdb103ca8f7c19/setup.py\", line 147, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/__init__.py\", line 103, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/dist.py\", line 963, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/wheel/bdist_wheel.py\", line 369, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"build\")\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/dist.py\", line 963, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/command/build.py\", line 131, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/dist.py\", line 963, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/command/build_ext.py\", line 88, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 345, in run\n",
      "  \u001b[31m   \u001b[0m     self.build_extensions()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 873, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     build_ext.build_extensions(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 467, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     self._build_extensions_serial()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 493, in _build_extensions_serial\n",
      "  \u001b[31m   \u001b[0m     self.build_extension(ext)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/command/build_ext.py\", line 249, in build_extension\n",
      "  \u001b[31m   \u001b[0m     _build_ext.build_extension(self, ext)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 548, in build_extension\n",
      "  \u001b[31m   \u001b[0m     objects = self.compiler.compile(\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 686, in unix_wrap_ninja_compile\n",
      "  \u001b[31m   \u001b[0m     _write_ninja_file_and_compile_objects(\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1774, in _write_ninja_file_and_compile_objects\n",
      "  \u001b[31m   \u001b[0m     _run_ninja_build(\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 2116, in _run_ninja_build\n",
      "  \u001b[31m   \u001b[0m     raise RuntimeError(message) from e\n",
      "  \u001b[31m   \u001b[0m RuntimeError: Error compiling objects for extension\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for torch-sparse\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for torch-sparse\n",
      "Failed to build torch-sparse\n",
      "\u001b[31mERROR: Could not build wheels for torch-sparse, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch-geometric in /home/wyrm/.local/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from torch-geometric) (4.64.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib64/python3.11/site-packages (from torch-geometric) (1.24.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib64/python3.11/site-packages (from torch-geometric) (1.10.0)\n",
      "Requirement already satisfied: jinja2 in /home/wyrm/.local/lib/python3.11/site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /home/wyrm/.local/lib/python3.11/site-packages (from torch-geometric) (2.28.1)\n",
      "Requirement already satisfied: pyparsing in /home/wyrm/.local/lib/python3.11/site-packages (from torch-geometric) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib64/python3.11/site-packages (from torch-geometric) (1.2.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/wyrm/.local/lib/python3.11/site-packages (from torch-geometric) (5.9.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/wyrm/.local/lib/python3.11/site-packages (from jinja2->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/wyrm/.local/lib/python3.11/site-packages (from requests->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wyrm/.local/lib/python3.11/site-packages (from requests->torch-geometric) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/wyrm/.local/lib/python3.11/site-packages (from requests->torch-geometric) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wyrm/.local/lib/python3.11/site-packages (from requests->torch-geometric) (2022.6.15)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/wyrm/.local/lib/python3.11/site-packages (from scikit-learn->torch-geometric) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn->torch-geometric) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
    "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-avenue",
   "metadata": {
    "id": "damaged-avenue"
   },
   "source": [
    "Ниже приведен общий модуль GNN, куда можно добавить любой реализованный слой GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incoming-pakistan",
   "metadata": {
    "id": "incoming-pakistan"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "#import torch_scatter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Union, Tuple, Optional\n",
    "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
    "                                    OptTensor)\n",
    "\n",
    "from torch.nn import Parameter, Linear\n",
    "# from torch_sparse import SparseTensor, set_diag\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "\n",
    "\n",
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):\n",
    "        super(GNNStack, self).__init__()\n",
    "        conv_model = self.build_conv_model(args.model_type)\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
    "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
    "        for l in range(args.num_layers-1):\n",
    "            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(args.heads * hidden_dim, hidden_dim), nn.Dropout(args.dropout), \n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.dropout = args.dropout\n",
    "        self.num_layers = args.num_layers\n",
    "\n",
    "        self.emb = emb\n",
    "\n",
    "    def build_conv_model(self, model_type):\n",
    "        if model_type == 'GraphSage':\n",
    "            return GraphSage\n",
    "        elif model_type == 'GAT':\n",
    "            # When applying GAT with num heads > 1, you need to modify the \n",
    "            # input and output dimension of the conv layers (self.convs),\n",
    "            # to ensure that the input dim of the next layer is num heads\n",
    "            # multiplied by the output dim of the previous layer.\n",
    "            # HINT: In case you want to play with multiheads, you need to change the for-loop that builds up self.convs to be\n",
    "            # self.convs.append(conv_model(hidden_dim * num_heads, hidden_dim)), \n",
    "            # and also the first nn.Linear(hidden_dim * num_heads, hidden_dim) in post-message-passing.\n",
    "            # implement \n",
    "            return GAT\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "          \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout,training=self.training)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        if self.emb == True:\n",
    "            return x\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-soccer",
   "metadata": {
    "id": "returning-soccer"
   },
   "source": [
    "### GCN (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-philosophy",
   "metadata": {
    "id": "athletic-philosophy"
   },
   "source": [
    "Слой GCN математически определяется как\n",
    "$$\\mathbf{x}_i^{(k)} = \\sum_{j \\in \\mathcal{N}(i) \\cup \\{ i \\}} \\frac{1}{\\sqrt{\\deg(i)} \\cdot \\sqrt{\\deg(j)}} \\cdot \\left( \\mathbf{W}^{\\top} \\cdot \\mathbf{x}_j^{(k-1)} \\right) + \\mathbf{b},$$\n",
    "\n",
    "где признаки соседних узлов сначала преобразуются матрицей весов $W$, нормализуются по их степени и суммируются. Наконец, мы применяем вектор смещения $b$ к агрегированному результату. Эту формулу можно разделить на следующие шаги:\n",
    "\n",
    "1. Добавить петли в матрицу смежности (можно использовать функцию add_self_loops из torch_geometric).\n",
    "2. Линейное преобразование матрицу призанков вершин.\n",
    "3. Вычисление коэффициентов нормализации.\n",
    "4. Нормирование призанаков вершин.\n",
    "5. Суммирование признаков соседних вершин (агрегация «add»).\n",
    "6. Применение вектора смещения.\n",
    "\n",
    "Шаги 1-3 обычно вычисляются до передачи сообщения. Шаги 4-5 можно легко выполнить с помощью базового класса MessagePassing. Ниже вам нужно реализовать методы *message* и *forward* на основе message passing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fatty-harris",
   "metadata": {
    "id": "fatty-harris"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "def drop_edge(edge_index, drop_rate=0.5):\n",
    "    num_keep = int(edge_index.shape[1] * (1 - drop_rate))\n",
    "    temp = [True] * num_keep + [False] * (edge_index.shape[1] - num_keep)\n",
    "    random.shuffle(temp)\n",
    "    return edge_index[:, temp]\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.lin = Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = Parameter(torch.Tensor(out_channels))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        edge_index = drop_edge(edge_index, drop_rate=0.2)\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        x = self.lin(x)\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "        return out + self.bias\n",
    "\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # TODO: Your code here! \n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-height",
   "metadata": {
    "id": "institutional-height"
   },
   "source": [
    "### GAT (6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-ancient",
   "metadata": {
    "id": "transparent-ancient"
   },
   "source": [
    "Ниже вам нужно реализовать методы *message*, *forward* и *aggregate* для Graph Attention Network слоя на основе message passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stainless-sunday",
   "metadata": {
    "id": "stainless-sunday"
   },
   "outputs": [],
   "source": [
    "class GAT(MessagePassing):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, heads = 2,\n",
    "                 negative_slope = 0.2, dropout = 0., **kwargs):\n",
    "        super(GAT, self).__init__(node_dim=0, **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.lin_l = None\n",
    "        self.lin_r = None\n",
    "        self.att_l = None\n",
    "        self.att_r = None\n",
    "\n",
    "        # TODO: Your code here!\n",
    "        self.lin_l = nn.Linear(self.in_channels, self.out_channels * self.heads)\n",
    "        # Define the layers needed for the message functions\n",
    "        # self.lin_l is the linear transformation that you apply to embeddings \n",
    "        # before message passing\n",
    "\n",
    "        self.lin_r = self.lin_l\n",
    "\n",
    "        # TODO: Your code here! \n",
    "        self.att_l = nn.Parameter(torch.zeros(self.heads, self.out_channels))\n",
    "        self.att_r = nn.Parameter(torch.zeros(self.heads, self.out_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.lin_l.weight)\n",
    "        nn.init.xavier_uniform_(self.lin_r.weight)\n",
    "        nn.init.xavier_uniform_(self.att_l)\n",
    "        nn.init.xavier_uniform_(self.att_r)\n",
    "\n",
    "    def forward(self, x, edge_index, size = None):\n",
    "        H, C = self.heads, self.out_channels\n",
    "        # TODO: Your code here! \n",
    "        x_l = self.lin_l(x).reshape(-1, H, C)\n",
    "        x_r = self.lin_r(x).reshape(-1, H, C)\n",
    "        alpha_l = self.att_l * x_l\n",
    "        alpha_r = self.att_r * x_r\n",
    "        out = self.propagate(edge_index, x=(x_l, x_r), alpha=(alpha_l, alpha_r), size=size)\n",
    "        out = out.reshape(-1, H*C)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n",
    "        # TODO: Your code here! \n",
    "        alpha = F.leaky_relu(alpha_i + alpha_j, negative_slope=self.negative_slope)\n",
    "        if ptr:\n",
    "            att_weight = F.softmax(alpha_i + alpha_j, ptr)\n",
    "        else:\n",
    "            att_weight = torch_geometric.utils.softmax(alpha_i + alpha_j, index)\n",
    "        att_weight = F.dropout(att_weight, p=self.dropout)\n",
    "        out = att_weight * x_j\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size = None):\n",
    "        # TODO: Your code here! \n",
    "        out = torch_scatter.scatter(inputs, index, self.node_dim, dim_size=dim_size, reduce='sum')\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-cattle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T21:07:57.081849Z",
     "start_time": "2022-11-02T21:07:57.075973Z"
    },
    "id": "nuclear-cattle"
   },
   "source": [
    "Ниже код для тестирования GNN слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "western-calvin",
   "metadata": {
    "id": "western-calvin"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def build_optimizer(args, params):\n",
    "    weight_decay = args.weight_decay\n",
    "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
    "    if args.opt == 'adam':\n",
    "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'sgd':\n",
    "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
    "    elif args.opt == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'adagrad':\n",
    "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    if args.opt_scheduler is None:\n",
    "        return None, optimizer\n",
    "    elif args.opt_scheduler == 'step':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
    "    elif args.opt_scheduler == 'cos':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
    "    return scheduler, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-curve",
   "metadata": {
    "id": "charitable-curve"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def train(dataset, args):\n",
    "    print(\"Node task. test set size:\", np.sum(dataset[0]['test_mask'].numpy()))\n",
    "    print()\n",
    "    test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    # build model\n",
    "    model = GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, \n",
    "                     args)\n",
    "    scheduler, opt = build_optimizer(args, model.parameters())\n",
    "\n",
    "    # train\n",
    "    losses = []\n",
    "    test_accs = []\n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            opt.zero_grad()\n",
    "            pred = model(batch)\n",
    "            label = batch.y\n",
    "            pred = pred[batch.train_mask]\n",
    "            label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        losses.append(total_loss)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_acc = test(test_loader, model)\n",
    "            test_accs.append(test_acc)\n",
    "            if test_acc > best_acc:\n",
    "                best_acc = test_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            test_accs.append(test_accs[-1])\n",
    "    \n",
    "    return test_accs, losses, best_model, best_acc, test_loader\n",
    "\n",
    "def test(loader, test_model, is_validation=False, save_model_preds=False, model_type=None):\n",
    "    test_model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    # Note that Cora is only one graph!\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            # max(dim=1) returns values, indices tuple; only need indices\n",
    "            pred = test_model(data).max(dim=1)[1]\n",
    "            label = data.y\n",
    "\n",
    "        mask = data.val_mask if is_validation else data.test_mask\n",
    "        # node classification: only evaluate on nodes in test set\n",
    "        pred = pred[mask]\n",
    "        label = label[mask]\n",
    "\n",
    "        if save_model_preds:\n",
    "            print (\"Saving Model Predictions for Model Type\", model_type)\n",
    "\n",
    "            data = {}\n",
    "            data['pred'] = pred.view(-1).cpu().detach().numpy()\n",
    "            data['label'] = label.view(-1).cpu().detach().numpy()\n",
    "\n",
    "        correct += pred.eq(label).sum().item()\n",
    "\n",
    "    total = 0\n",
    "    for data in loader.dataset:\n",
    "        total += torch.sum(data.val_mask if is_validation else data.test_mask).item()\n",
    "\n",
    "    return correct / total\n",
    "  \n",
    "class ObjectView(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-representation",
   "metadata": {
    "id": "successful-representation"
   },
   "outputs": [],
   "source": [
    "args = ObjectView({\n",
    "    'model_type': 'GraphSage',\n",
    "    'dataset': 'cora',\n",
    "    'num_layers': 2,\n",
    "    'heads': 1,\n",
    "    'batch_size': 32,\n",
    "    'hidden_dim': 32,\n",
    "    'dropout': 0.3,\n",
    "    'epochs': 500,\n",
    "    'opt': 'adam',\n",
    "    'opt_scheduler': None,\n",
    "    'opt_restart': 0,\n",
    "    'weight_decay': 5e-3,\n",
    "    'lr': 0.01\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-hobby",
   "metadata": {
    "id": "novel-hobby"
   },
   "source": [
    "Настройте аргументы и запустите функции train и test на разных блоках (*GraphSAGE* с семинара, *GCN*, *GAT*) на датасете Cora и на любом другом на выбор из доступных в библиотеке torch_geometric и сравните полученное качество на разных слоях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSage(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, normalize=True,\n",
    "                 bias=False, **kwargs):\n",
    "        super(GraphSage, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.lin_l = torch.nn.Linear(in_channels, out_channels, bias=bias)\n",
    "        self.lin_r = torch.nn.Linear(in_channels, out_channels, bias=bias)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_l.reset_parameters()\n",
    "        self.lin_r.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, size=None):\n",
    "        # x is shape (N, in_c)\n",
    "        neighbor_out = self.propagate(edge_index, x=(x, x), size=size)\n",
    "        out = self.lin_l(x) + self.lin_r(neighbor_out)\n",
    "        if self.normalize:\n",
    "            out = torch.nn.functional.normalize(out, p=2)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):\n",
    "        # x_j has shape (E, d)\n",
    "        out = x_j\n",
    "        return out\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size=None):\n",
    "        node_dim = self.node_dim\n",
    "\n",
    "        out = torch_scatter.scatter(inputs, index, dim=node_dim, reduce='mean')\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-measure",
   "metadata": {
    "id": "regulation-measure"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "charitable-ranch",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T21:08:21.821439Z",
     "start_time": "2022-11-02T21:08:21.816723Z"
    },
    "id": "charitable-ranch"
   },
   "source": [
    "Также поэксперементируйте с параметрами сетей и на основе экспериментов ниже напишите выводы. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-drunk",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T20:55:14.854665Z",
     "start_time": "2022-11-02T20:55:14.816633Z"
    },
    "id": "suited-drunk"
   },
   "source": [
    "__Отчет по экспериментам:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-damage",
   "metadata": {
    "id": "vietnamese-damage"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "useful-scoop",
   "metadata": {
    "id": "useful-scoop"
   },
   "source": [
    "### Бонус (1 балл)\n",
    "* Прикрепить ссылку на отчет по экспериментам из wandb (1 балл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-restaurant",
   "metadata": {
    "id": "advisory-restaurant"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
