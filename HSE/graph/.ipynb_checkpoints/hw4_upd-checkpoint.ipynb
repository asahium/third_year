{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85426f5a",
   "metadata": {
    "id": "85426f5a"
   },
   "source": [
    "# Домашнее задание 4\n",
    "\n",
    "## Глубинное обучение в анализе графовых данных, ПМИ ВШЭ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d0553e",
   "metadata": {
    "id": "41d0553e"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
    "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "# !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "# !pip install git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35463c99",
   "metadata": {
    "id": "35463c99"
   },
   "source": [
    "## 1. Реализация TransE (10 баллов)\n",
    "\n",
    "В этом задании требуется реализовать пайплайн обучения эмбдеддингов графа знаний с помощью [TransE](https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf) для задачи прогнозирования отсутствующих ребер на наборе данных [Freebase](https://paperswithcode.com/dataset/fb15k) (FB15k-237), а также реализовать саму модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a2166d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T16:38:28.749186Z",
     "start_time": "2022-11-28T16:38:28.620681Z"
    },
    "id": "c5a2166d"
   },
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.datasets.rel_link_pred_dataset import RelLinkPredDataset\n",
    "\n",
    "\n",
    "dataset = RelLinkPredDataset('data', 'FB15k-237')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee68c8b9",
   "metadata": {
    "id": "ee68c8b9"
   },
   "source": [
    "#### TransE\n",
    "Ребра в графе знаний представляются тройками $(h, r, t)$. В TransE мы моделируем как объекты, так и отношения в пространстве эмбеддингов и пытаемся получить эмбеддинги, как $\\textbf h + \\textbf l \\approx \\textbf t$. Формально loss выглядит:\n",
    "\n",
    "$$\\sum_{((h, l, t), (h', l, t')) \\in T_{batch}} [\\gamma + d(\\textbf{h} + \\textbf{l}, \\textbf t) - d(\\textbf{h'} + \\textbf l, \\textbf{t'})]$$\n",
    "\n",
    "где $(h', l, t')$ представляет собой тройку, заменяя head или tail случайным объектом.\n",
    "$d(\\boldsymbol{h}+\\boldsymbol{l}, \\boldsymbol{t})$ – показатель _различия_ положительного ребра. Кроме того, $d\\left(\\boldsymbol{h}^{\\prime}+\\boldsymbol{l}, \\boldsymbol{t}^{\\prime}\\right)$ — это оценка _различия_ для отрицательной тройки, полученная изменением либо head, либо tail (но не оба) положительной тройки. Таким образом, TransE *предпочитает* более низкие оценки для положительных ребер и большие оценки для отрицательных ребер.\n",
    "\n",
    "Что касается параметра $\\gamma$, он используется для обеспечения того, чтобы оценка положительного ребра отличалась от оценки отрицательного ребра как минимум на $\\gamma$.\n",
    "\n",
    "Итого алгоритм TransE выглядит следующим образом:\n",
    "\n",
    "![](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-05-27_at_12.01.23_AM.png)\n",
    "\n",
    "Что касается реализации модели, можно инициализировать $\\textbf l$ и $\\textbf e$ в соответствии с приведенным выше псевдокодом. Чтобы вычислить $d(\\textbf{h} + \\textbf{l}, \\textbf t)$, нужно взять L2-норму $\\textbf h + \\textbf l - \\textbf t$.\n",
    "\n",
    "*Примечание: для повышения производительности можно нормализовать $\\textbf e$ каждую эпоху, а не каждый мини-батч.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdea747a",
   "metadata": {
    "id": "cdea747a"
   },
   "source": [
    "__Вспомогательные функции:__\n",
    "\n",
    "Одним из ключевых аспектов обучения модели является создание измененных троек путем замены head или tail случайным объектом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecfe5efd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T15:59:33.777084Z",
     "start_time": "2022-11-28T15:59:33.771787Z"
    },
    "id": "ecfe5efd"
   },
   "outputs": [],
   "source": [
    "def create_neg_edge_index(edge_index, edge_type, num_entities):\n",
    "    head_or_tail = torch.randint(high=2, size=edge_type.size(),\n",
    "                                 device=device)\n",
    "    rand_entities = torch.randint(high=num_entities,\n",
    "                                  size=edge_type.size(), device=device)\n",
    "    # change when 1, otherwise regular head\n",
    "    heads = torch.where(head_or_tail == 1, rand_entities,\n",
    "                        edge_index[0, :])\n",
    "    # change when 0, otherwise regular tail\n",
    "    tails = torch.where(head_or_tail == 0, rand_entities,\n",
    "                        edge_index[1, :])\n",
    "    return torch.stack([heads, tails], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afac228",
   "metadata": {
    "id": "0afac228"
   },
   "source": [
    "Оценивать качество будем по Hits@10, Mean Rank и MRR (mean reciprocal rank).\n",
    "\n",
    "Hits@10 = $\\frac{|\\{r \\in P | r \\leq 10\\}|}{|P|}$, где $|P|$ — количество оценок, а $r$ — ранг.\n",
    "\n",
    "Mean Rank = $\\frac{1}{|P|}\\sum_{r \\in P}r$\n",
    "\n",
    "MMR = $\\frac{1}{|P|}\\sum_{r \\in P}\\frac{1}{r}$\n",
    "\n",
    "Подробнее о метриках можно узнать [здесь](https://arxiv.org/pdf/2002.06914.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e064eec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T15:59:34.258096Z",
     "start_time": "2022-11-28T15:59:34.249708Z"
    },
    "id": "2e064eec"
   },
   "outputs": [],
   "source": [
    "def mrr(predictions, gt):\n",
    "    indices = predictions.argsort()\n",
    "    return (1.0 / (indices == gt).nonzero()[:, 1].float().add(1.0)).sum().item()\n",
    "\n",
    "\n",
    "def mr(predictions, gt):\n",
    "    indices = predictions.argsort()\n",
    "    return ((indices == gt).nonzero()[:, 1].float().add(1.0)).sum().item()\n",
    "\n",
    "\n",
    "def hit_at_k(predictions, gt, device, k=10):\n",
    "    zero_tensor = torch.tensor([0], device=device)\n",
    "    one_tensor = torch.tensor([1], device=device)\n",
    "    _, indices = predictions.topk(k=k, largest=False)\n",
    "    return torch.where(indices == gt, one_tensor, zero_tensor).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2193ce2f",
   "metadata": {
    "id": "2193ce2f"
   },
   "source": [
    "__Требуется__ добиться качества хотя бы 0.17 MRR и 0.30 Hits@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a31ef0",
   "metadata": {
    "id": "c1a31ef0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils import data\n",
    "\n",
    "model_path = './train_model/best_model'\n",
    "data_path = './data/FB15K'\n",
    "train_batch_size = 1024\n",
    "eval_batch_size = 512\n",
    "epochs = 100 # 2000\n",
    "learning_rate = 0.1\n",
    "\n",
    "hidden_size = 50\n",
    "eval_freq = 25\n",
    "margin = 1.\n",
    "seed = 3435\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(path) :\n",
    "    output_dict = {}\n",
    "\n",
    "    for line in open(path, 'r').readlines()[1:] :\n",
    "        key, value = line.strip().split('\\t')\n",
    "        output_dict[key] = int(value)\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "class FB15K_Dataset(data.Dataset) :\n",
    "    def __init__(self, path, entity2id, relation2id):\n",
    "        self.entity2id = entity2id\n",
    "        self.relation2id = relation2id\n",
    "\n",
    "        self.data = []\n",
    "        for line in open(path, 'r').readlines()[1:]:\n",
    "            self.data.append(list(map(int, line.strip().split())))\n",
    "            # str -> int (sbj_id, obj_id, rel_id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity to id :  [('/m/027rn', 0), ('/m/06cx9', 1), ('/m/017dcd', 2), ('/m/06v8s0', 3), ('/m/07s9rl0', 4)]\n",
      "relation to id :  [('/location/country/form_of_government', 0), ('/tv/tv_program/regular_cast./tv/regular_tv_appearance/actor', 1), ('/media_common/netflix_genre/titles', 2), ('/award/award_winner/awards_won./award/award_honor/award_winner', 3), ('/soccer/football_team/current_roster./sports/sports_team_roster/position', 4)]\n"
     ]
    }
   ],
   "source": [
    "entity2id = load_dict(os.path.join(data_path, 'entity2id.txt'))\n",
    "relation2id = load_dict(os.path.join(data_path, 'relation2id.txt'))\n",
    "\n",
    "train_dataset = FB15K_Dataset(os.path.join(data_path, 'train2id.txt'), entity2id, relation2id)\n",
    "dev_dataset = FB15K_Dataset(os.path.join(data_path, 'valid2id.txt'), entity2id, relation2id)\n",
    "test_dataset = FB15K_Dataset(os.path.join(data_path, 'test2id.txt'), entity2id, relation2id)\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset,\n",
    "                               batch_size=train_batch_size,\n",
    "                               shuffle=True)\n",
    "dev_loader = data.DataLoader(dev_dataset,\n",
    "                             batch_size=eval_batch_size,\n",
    "                             shuffle=False)\n",
    "test_loader = data.DataLoader(test_dataset,\n",
    "                              batch_size=eval_batch_size,\n",
    "                              shuffle=False)\n",
    "\n",
    "print('entity to id : ', [(key, val) for key, val in entity2id.items()][:5])\n",
    "print('relation to id : ', [(key, val) for key, val in relation2id.items()][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransE(nn.Module):\n",
    "    def __init__(self, n_entity, n_relation, hidden_size, margin=1.0, device=True):\n",
    "        super(TransE, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.n_entity = n_entity\n",
    "        self.n_relation = n_relation\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.entity_embedding = nn.Embedding(self.n_entity + 1, self.hidden_size, padding_idx=self.n_entity)\n",
    "        self.relation_embedding = nn.Embedding(self.n_relation + 1, self.hidden_size, padding_idx=self.n_relation)\n",
    "\n",
    "        self.init_weight(self.entity_embedding)\n",
    "        self.init_weight(self.relation_embedding)\n",
    "\n",
    "        self.loss_func = nn.MarginRankingLoss(margin=margin, reduction='none')\n",
    "\n",
    "    def init_weight(self, embedding):\n",
    "        n_vocab, hidden_dim = embedding.weight.data.size()\n",
    "        sqrt_dim = hidden_dim ** 0.5\n",
    "\n",
    "        embedding.weight.data = torch.FloatTensor(n_vocab, hidden_dim).uniform_(-6./sqrt_dim, 6./sqrt_dim)\n",
    "        embedding.weight.data = F.normalize(embedding.weight.data, 2, 1)\n",
    "\n",
    "    def get_score(self, triple):\n",
    "        sbj, rel, obj = triple[:, 0], triple[:, 1], triple[:, 2]\n",
    "\n",
    "        sbj_embedding = self.entity_embedding(sbj)\n",
    "        rel_embedding = self.relation_embedding(rel)\n",
    "        obj_embedding = self.entity_embedding(obj)\n",
    "\n",
    "        score = torch.norm((sbj_embedding + rel_embedding - obj_embedding), p=1, dim=1)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def forward(self, positive_triple, negative_triple):\n",
    "        positive_score = self.get_score(positive_triple)\n",
    "        negative_score = self.get_score(negative_triple)\n",
    "\n",
    "        y = torch.tensor([-1.], dtype=torch.float, device=self.device)\n",
    "\n",
    "        return self.loss_func(positive_score, negative_score, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hit_at_k(pred, answer, device, k=10) :\n",
    "#     zero_tensor = torch.tensor([0], device=device)\n",
    "#     one_tensor = torch.tensor([1], device=device)\n",
    "\n",
    "#     _, indices = pred.topk(k=k, largest=False)\n",
    "\n",
    "#     return torch.where(indices == answer.unsqueeze(1), one_tensor, zero_tensor).sum().item()\n",
    "\n",
    "# def MRR(pred, answer) :\n",
    "#     return (1. / (pred.argsort() == answer.unsqueeze(1)).nonzero()[:, 1].float().add(1.)).sum().item()\n",
    "\n",
    "def evaluation(model, data_loader, device) :\n",
    "    model.eval() # evaluation mode\n",
    "    hit_at_1, hit_at_3, hit_at_10, mrr, total = 0., 0., 0., 0., 0.\n",
    "\n",
    "    entity_ids = torch.arange(model.n_entity, device=device).unsqueeze(0)\n",
    "\n",
    "    for sbj, obj, rel in data_loader :\n",
    "        sbj, rel, obj = sbj.to(device), rel.to(device), obj.to(device)  # to GPU\n",
    "        b_size = sbj.size(0)\n",
    "        all_entity = entity_ids.repeat(b_size, 1)\n",
    "        repeat_sbj = sbj.unsqueeze(1).repeat(1, all_entity.size(1))\n",
    "        repeat_rel = rel.unsqueeze(1).repeat(1, all_entity.size(1))\n",
    "        repeat_obj = obj.unsqueeze(1).repeat(1, all_entity.size(1))\n",
    "\n",
    "        sbj_triples = torch.stack((repeat_sbj, repeat_rel, all_entity), dim=2).view(-1, 3)\n",
    "        obj_triples = torch.stack((all_entity, repeat_rel, repeat_obj), dim=2).view(-1, 3)\n",
    "\n",
    "        obj_pred_score = model.get_score(sbj_triples).view(b_size, -1)\n",
    "        sbj_pred_score = model.get_score(obj_triples).view(b_size, -1)\n",
    "\n",
    "        pred = torch.cat([sbj_pred_score, obj_pred_score], dim=0)\n",
    "        answer = torch.cat([sbj, obj], dim=0)\n",
    "\n",
    "        hit_at_1 += hit_at_k(pred, answer, device, k=1)\n",
    "        hit_at_3 += hit_at_k(pred, answer, device, k=3)\n",
    "        hit_at_10 += hit_at_k(pred, answer, device, k=10)\n",
    "\n",
    "        mrr += mrr(pred, answer)\n",
    "        total += pred.size(0)\n",
    "\n",
    "    hit_at_1_score = hit_at_1 / total * 100.\n",
    "    hit_at_3_score = hit_at_3 / total * 100.\n",
    "    hit_at_10_score = hit_at_10 / total * 100.\n",
    "    mrr_score = mrr / total * 100.\n",
    "\n",
    "    return hit_at_1_score, hit_at_3_score, hit_at_10_score, mrr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure : TransE(\n",
      "  (entity_embedding): Embedding(14952, 50, padding_idx=14951)\n",
      "  (relation_embedding): Embedding(1346, 50, padding_idx=1345)\n",
      "  (loss_func): MarginRankingLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = TransE(n_entity=len(entity2id),\n",
    "                n_relation=len(relation2id),\n",
    "                hidden_size=hidden_size,\n",
    "                margin=margin,\n",
    "                device=device)\n",
    "model.to(device) # to GPU\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print('Model Structure : {}'.format(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, loss = 1.023869\n",
      "Epoch = 2, loss = 0.913122\n",
      "Epoch = 3, loss = 0.804188\n",
      "Epoch = 4, loss = 0.836700\n",
      "Epoch = 5, loss = 0.800225\n",
      "Epoch = 6, loss = 0.735314\n",
      "Epoch = 7, loss = 0.741244\n",
      "Epoch = 8, loss = 0.722705\n",
      "Epoch = 9, loss = 0.703607\n",
      "Epoch = 10, loss = 0.667580\n",
      "Epoch = 11, loss = 0.681190\n",
      "Epoch = 12, loss = 0.637469\n",
      "Epoch = 13, loss = 0.615523\n",
      "Epoch = 14, loss = 0.600525\n",
      "Epoch = 15, loss = 0.607204\n",
      "Epoch = 16, loss = 0.588883\n",
      "Epoch = 17, loss = 0.555680\n",
      "Epoch = 18, loss = 0.589581\n",
      "Epoch = 19, loss = 0.538721\n",
      "Epoch = 20, loss = 0.547970\n",
      "Epoch = 21, loss = 0.573983\n",
      "Epoch = 22, loss = 0.556399\n",
      "Epoch = 23, loss = 0.521527\n",
      "Epoch = 24, loss = 0.526862\n",
      "Epoch = 25, loss = 0.462608\n",
      "evaluation...\n"
     ]
    }
   ],
   "source": [
    "best_score = 0.\n",
    "for epoch in range(1, epochs+1) :\n",
    "    model.train() # train mode\n",
    "    for i, (sbj, obj, rel) in enumerate(train_loader) :\n",
    "        sbj, rel, obj = sbj.to(device), rel.to(device), obj.to(device)  # to GPU\n",
    "\n",
    "        positive_triples = torch.stack((sbj, rel, obj), dim=1) # (batch) * 3 -> (batch, 3)\n",
    "\n",
    "        # Negative sampling\n",
    "        head_or_tail = torch.randint(high=2, size=sbj.size(), device=device)\n",
    "        random_entities = torch.randint(high=len(entity2id), size=sbj.size(), device=device)\n",
    "        neg_sbj = torch.where(head_or_tail == 1, random_entities, sbj)\n",
    "        neg_obj = torch.where(head_or_tail == 0, random_entities, obj)\n",
    "        negative_triples = torch.stack((neg_sbj, rel, neg_obj), dim=1) # (batch) * 3 -> (batch, 3)\n",
    "\n",
    "        loss = model(positive_triples, negative_triples).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print('Epoch = {}, loss = {:.6f}'. format(epoch, loss))\n",
    "    if(epoch % eval_freq == 0) :\n",
    "        print('evaluation...')      \n",
    "        hit_at_1_score, hit_at_3_score, hit_at_10_score, mrr_score = evaluation(model, dev_loader, device)\n",
    "\n",
    "        print('Dev set >> hit@1 : {:.2f}, hit@3 : {:.2f}, hit@10 : {:.2f}, mrr : {:.2f}'.format(hit_at_1_score,\n",
    "                                                                                                hit_at_3_score,\n",
    "                                                                                                hit_at_10_score,\n",
    "                                                                                                mrr_score))\n",
    "        if(hit_at_10_score > best_score) :\n",
    "            print('best model save...')\n",
    "            state_dict = model.state_dict()\n",
    "            torch.save(state_dict, model_path)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "hit_at_1_score, hit_at_3_score, hit_at_10_score, mrr_score = evaluation(model, test_loader, device)\n",
    "\n",
    "print('Test Set >> hit@1 : {:.2f}, hit@3 : {:.2f}, hit@10 : {:.2f}, mrr : {:.2f}'.format(hit_at_1_score,\n",
    "                                                                                         hit_at_3_score,\n",
    "                                                                                         hit_at_10_score,\n",
    "                                                                                         mrr_score))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dqZlPjwNyac_",
   "metadata": {
    "id": "dqZlPjwNyac_"
   },
   "source": [
    "### 1.1 Вопрос о нормализации (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_ZnyvNQdy-SH",
   "metadata": {
    "id": "_ZnyvNQdy-SH"
   },
   "source": [
    "Попробуйте обучить TransE без пятой строчки алгоритма (без нормализации по сущностям). Что происходит с обучением? Зачем требуется эта строка?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2767859c",
   "metadata": {
    "id": "2767859c"
   },
   "source": [
    "## 2. Нейросеть на гетерогенных данных (3 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LFkv3s8sykyG",
   "metadata": {
    "id": "LFkv3s8sykyG"
   },
   "source": [
    "Возьмите один из 2 датасетов (Freebase/ синтетический датасет hetero_graph далее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deGDhKWeCi3k",
   "metadata": {
    "id": "deGDhKWeCi3k"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dgl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m dislike_src \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, n_users, n_dislikes)\n\u001b[1;32m     18\u001b[0m dislike_dst \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, n_items, n_dislikes)\n\u001b[0;32m---> 20\u001b[0m hetero_graph \u001b[38;5;241m=\u001b[39m \u001b[43mdgl\u001b[49m\u001b[38;5;241m.\u001b[39mheterograph({\n\u001b[1;32m     21\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfollow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m): (follow_src, follow_dst),\n\u001b[1;32m     22\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfollowed-by\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m): (follow_dst, follow_src),\n\u001b[1;32m     23\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclick\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m'\u001b[39m): (click_src, click_dst),\n\u001b[1;32m     24\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclicked-by\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m): (click_dst, click_src),\n\u001b[1;32m     25\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdislike\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m'\u001b[39m): (dislike_src, dislike_dst),\n\u001b[1;32m     26\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisliked-by\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m): (dislike_dst, dislike_src)})\n\u001b[1;32m     28\u001b[0m hetero_graph\u001b[38;5;241m.\u001b[39mnodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(n_users, n_hetero_features)\n\u001b[1;32m     29\u001b[0m hetero_graph\u001b[38;5;241m.\u001b[39mnodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(n_items, n_hetero_features)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dgl' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "n_users = 1000\n",
    "n_items = 500\n",
    "n_follows = 3000\n",
    "n_clicks = 5000\n",
    "n_dislikes = 500\n",
    "n_hetero_features = 10\n",
    "n_user_classes = 5\n",
    "n_max_clicks = 10\n",
    "\n",
    "follow_src = np.random.randint(0, n_users, n_follows)\n",
    "follow_dst = np.random.randint(0, n_users, n_follows)\n",
    "click_src = np.random.randint(0, n_users, n_clicks)\n",
    "click_dst = np.random.randint(0, n_items, n_clicks)\n",
    "dislike_src = np.random.randint(0, n_users, n_dislikes)\n",
    "dislike_dst = np.random.randint(0, n_items, n_dislikes)\n",
    "\n",
    "hetero_graph = dgl.heterograph({\n",
    "    ('user', 'follow', 'user'): (follow_src, follow_dst),\n",
    "    ('user', 'followed-by', 'user'): (follow_dst, follow_src),\n",
    "    ('user', 'click', 'item'): (click_src, click_dst),\n",
    "    ('item', 'clicked-by', 'user'): (click_dst, click_src),\n",
    "    ('user', 'dislike', 'item'): (dislike_src, dislike_dst),\n",
    "    ('item', 'disliked-by', 'user'): (dislike_dst, dislike_src)})\n",
    "\n",
    "hetero_graph.nodes['user'].data['feature'] = torch.randn(n_users, n_hetero_features)\n",
    "hetero_graph.nodes['item'].data['feature'] = torch.randn(n_items, n_hetero_features)\n",
    "hetero_graph.nodes['user'].data['label'] = torch.randint(0, n_user_classes, (n_users,))\n",
    "hetero_graph.edges['click'].data['label'] = torch.randint(1, n_max_clicks, (n_clicks,)).float()\n",
    "# randomly generate training masks on user nodes and click edges\n",
    "hetero_graph.nodes['user'].data['train_mask'] = torch.zeros(n_users, dtype=torch.bool).bernoulli(0.6)\n",
    "hetero_graph.edges['click'].data['train_mask'] = torch.zeros(n_clicks, dtype=torch.bool).bernoulli(0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vOwWWxfCDPEK",
   "metadata": {
    "id": "vOwWWxfCDPEK"
   },
   "source": [
    "Используя любую библиотеку (torch geometry, dgl, stellargraph) соберите нейронную сеть и обучите ее (решать задачу Node Classification) на одном из двух датасетов выше.\n",
    "\n",
    "**БОНУСЫ:** \n",
    "(2 балла) Обучите нейросеть решать задачу link prediction\n",
    "\n",
    "(1 балл) возьмите еще какой-нибудь гетерогенный датасет (не маленький и не синтетический) и обучите на нем\n",
    "\n",
    "(4 балла) реализуйте самостоятельно Relational GCN и продемонстрируйте работоспобность вашего слоя. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T-QdveYJDaUY",
   "metadata": {
    "id": "T-QdveYJDaUY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
