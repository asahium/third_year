{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "understanding-software",
   "metadata": {
    "id": "understanding-software"
   },
   "source": [
    "# Домашнее задание 2 \n",
    "\n",
    "## Глубинное обучение в анализе графовых данных, ПМИ ВШЭ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-freeze",
   "metadata": {
    "id": "declared-freeze"
   },
   "source": [
    "В этом дз для мониторинга экспериментов лучше использовать сервис __wandb__, [здесь](https://docs.wandb.ai/quickstart) можете ознакомиться с документацией"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-fisher",
   "metadata": {
    "id": "certain-fisher"
   },
   "source": [
    "### 1. PageRank Personalized (1 балл)\n",
    "\n",
    "Реализуйте на основе кода с семинара персонализованный алгоритм PageRank с опцией возвращения в одну точку (индекс который подается в keep_updating_until_convergence(...)), либо же topic-related с возможностью вернуться в определенный массив точек (подается в эту же функцию). Подумайте над реализацией, опишите как вы решили модифицирвоать алгоритм, продемонстрируйте работспособность на каком-нибудь искуственном наборе данных (можно двудольном). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-onion",
   "metadata": {
    "id": "headed-onion"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-carnival",
   "metadata": {
    "id": "enclosed-carnival"
   },
   "source": [
    "### Реализация слоев графовых нейронных сетей для классификации вершин"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-newman",
   "metadata": {
    "id": "lined-newman"
   },
   "source": [
    "На 5ом семинаре мы реализовали слой **GraphSAGE** ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)). Здесь вы должны реализовать еще более мощные слои: **GAT** ([Veličković et al. (2018)](https://arxiv.org/abs/1710.10903)) и **GCN** ([Kipf et al. (2017)](https://arxiv.org/abs/1609.02907)). Затем вы должны запустить модели для решения задачи классификации вершин на наборе данных CORA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-fleet",
   "metadata": {
    "id": "placed-fleet"
   },
   "outputs": [],
   "source": [
    "# !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
    "# !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
    "# !pip install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-avenue",
   "metadata": {
    "id": "damaged-avenue"
   },
   "source": [
    "Ниже приведен общий модуль GNN, куда можно добавить любой реализованный слой GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-pakistan",
   "metadata": {
    "id": "incoming-pakistan"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_scatter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Union, Tuple, Optional\n",
    "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
    "                                    OptTensor)\n",
    "\n",
    "from torch.nn import Parameter, Linear\n",
    "from torch_sparse import SparseTensor, set_diag\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "\n",
    "\n",
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):\n",
    "        super(GNNStack, self).__init__()\n",
    "        conv_model = self.build_conv_model(args.model_type)\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
    "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
    "        for l in range(args.num_layers-1):\n",
    "            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(args.heads * hidden_dim, hidden_dim), nn.Dropout(args.dropout), \n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.dropout = args.dropout\n",
    "        self.num_layers = args.num_layers\n",
    "\n",
    "        self.emb = emb\n",
    "\n",
    "    def build_conv_model(self, model_type):\n",
    "        if model_type == 'GraphSage':\n",
    "            return GraphSage\n",
    "        elif model_type == 'GAT':\n",
    "            # When applying GAT with num heads > 1, you need to modify the \n",
    "            # input and output dimension of the conv layers (self.convs),\n",
    "            # to ensure that the input dim of the next layer is num heads\n",
    "            # multiplied by the output dim of the previous layer.\n",
    "            # HINT: In case you want to play with multiheads, you need to change the for-loop that builds up self.convs to be\n",
    "            # self.convs.append(conv_model(hidden_dim * num_heads, hidden_dim)), \n",
    "            # and also the first nn.Linear(hidden_dim * num_heads, hidden_dim) in post-message-passing.\n",
    "            return GAT\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "          \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout,training=self.training)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        if self.emb == True:\n",
    "            return x\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-soccer",
   "metadata": {
    "id": "returning-soccer"
   },
   "source": [
    "### GCN (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-philosophy",
   "metadata": {
    "id": "athletic-philosophy"
   },
   "source": [
    "Слой GCN математически определяется как\n",
    "$$\\mathbf{x}_i^{(k)} = \\sum_{j \\in \\mathcal{N}(i) \\cup \\{ i \\}} \\frac{1}{\\sqrt{\\deg(i)} \\cdot \\sqrt{\\deg(j)}} \\cdot \\left( \\mathbf{W}^{\\top} \\cdot \\mathbf{x}_j^{(k-1)} \\right) + \\mathbf{b},$$\n",
    "\n",
    "где признаки соседних узлов сначала преобразуются матрицей весов $W$, нормализуются по их степени и суммируются. Наконец, мы применяем вектор смещения $b$ к агрегированному результату. Эту формулу можно разделить на следующие шаги:\n",
    "\n",
    "1. Добавить петли в матрицу смежности (можно использовать функцию add_self_loops из torch_geometric).\n",
    "2. Линейное преобразование матрицу призанков вершин.\n",
    "3. Вычисление коэффициентов нормализации.\n",
    "4. Нормирование призанаков вершин.\n",
    "5. Суммирование признаков соседних вершин (агрегация «add»).\n",
    "6. Применение вектора смещения.\n",
    "\n",
    "Шаги 1-3 обычно вычисляются до передачи сообщения. Шаги 4-5 можно легко выполнить с помощью базового класса MessagePassing. Ниже вам нужно реализовать методы *message* и *forward* на основе message passing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-harris",
   "metadata": {
    "id": "fatty-harris"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.lin = Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = Parameter(torch.Tensor(out_channels))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # TODO: Your code here! \n",
    "        pass\n",
    "\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # TODO: Your code here! \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-height",
   "metadata": {
    "id": "institutional-height"
   },
   "source": [
    "### GAT (6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-ancient",
   "metadata": {
    "id": "transparent-ancient"
   },
   "source": [
    "Ниже вам нужно реализовать методы *message*, *forward* и *aggregate* для Graph Attention Network слоя на основе message passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-sunday",
   "metadata": {
    "id": "stainless-sunday"
   },
   "outputs": [],
   "source": [
    "class GAT(MessagePassing):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, heads = 2,\n",
    "                 negative_slope = 0.2, dropout = 0., **kwargs):\n",
    "        super(GAT, self).__init__(node_dim=0, **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.lin_l = None\n",
    "        self.lin_r = None\n",
    "        self.att_l = None\n",
    "        self.att_r = None\n",
    "\n",
    "        # TODO: Your code here!\n",
    "        \n",
    "        # Define the layers needed for the message functions\n",
    "        # self.lin_l is the linear transformation that you apply to embeddings \n",
    "        # before message passing\n",
    "\n",
    "        self.lin_r = self.lin_l\n",
    "\n",
    "        # TODO: Your code here! \n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.lin_l.weight)\n",
    "        nn.init.xavier_uniform_(self.lin_r.weight)\n",
    "        nn.init.xavier_uniform_(self.att_l)\n",
    "        nn.init.xavier_uniform_(self.att_r)\n",
    "\n",
    "    def forward(self, x, edge_index, size = None):\n",
    "        H, C = self.heads, self.out_channels\n",
    "        # TODO: Your code here! \n",
    "        pass\n",
    "\n",
    "\n",
    "    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n",
    "        # TODO: Your code here! \n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size = None):\n",
    "        # TODO: Your code here! \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-cattle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T21:07:57.081849Z",
     "start_time": "2022-11-02T21:07:57.075973Z"
    },
    "id": "nuclear-cattle"
   },
   "source": [
    "Ниже код для тестирования GNN слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-calvin",
   "metadata": {
    "id": "western-calvin"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def build_optimizer(args, params):\n",
    "    weight_decay = args.weight_decay\n",
    "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
    "    if args.opt == 'adam':\n",
    "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'sgd':\n",
    "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
    "    elif args.opt == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'adagrad':\n",
    "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    if args.opt_scheduler is None:\n",
    "        return None, optimizer\n",
    "    elif args.opt_scheduler == 'step':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
    "    elif args.opt_scheduler == 'cos':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
    "    return scheduler, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-curve",
   "metadata": {
    "id": "charitable-curve"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def train(dataset, args):\n",
    "    print(\"Node task. test set size:\", np.sum(dataset[0]['test_mask'].numpy()))\n",
    "    print()\n",
    "    test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    # build model\n",
    "    model = GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, \n",
    "                     args)\n",
    "    scheduler, opt = build_optimizer(args, model.parameters())\n",
    "\n",
    "    # train\n",
    "    losses = []\n",
    "    test_accs = []\n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            opt.zero_grad()\n",
    "            pred = model(batch)\n",
    "            label = batch.y\n",
    "            pred = pred[batch.train_mask]\n",
    "            label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        losses.append(total_loss)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_acc = test(test_loader, model)\n",
    "            test_accs.append(test_acc)\n",
    "            if test_acc > best_acc:\n",
    "                best_acc = test_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            test_accs.append(test_accs[-1])\n",
    "    \n",
    "    return test_accs, losses, best_model, best_acc, test_loader\n",
    "\n",
    "def test(loader, test_model, is_validation=False, save_model_preds=False, model_type=None):\n",
    "    test_model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    # Note that Cora is only one graph!\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            # max(dim=1) returns values, indices tuple; only need indices\n",
    "            pred = test_model(data).max(dim=1)[1]\n",
    "            label = data.y\n",
    "\n",
    "        mask = data.val_mask if is_validation else data.test_mask\n",
    "        # node classification: only evaluate on nodes in test set\n",
    "        pred = pred[mask]\n",
    "        label = label[mask]\n",
    "\n",
    "        if save_model_preds:\n",
    "            print (\"Saving Model Predictions for Model Type\", model_type)\n",
    "\n",
    "            data = {}\n",
    "            data['pred'] = pred.view(-1).cpu().detach().numpy()\n",
    "            data['label'] = label.view(-1).cpu().detach().numpy()\n",
    "\n",
    "        correct += pred.eq(label).sum().item()\n",
    "\n",
    "    total = 0\n",
    "    for data in loader.dataset:\n",
    "        total += torch.sum(data.val_mask if is_validation else data.test_mask).item()\n",
    "\n",
    "    return correct / total\n",
    "  \n",
    "class ObjectView(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-representation",
   "metadata": {
    "id": "successful-representation"
   },
   "outputs": [],
   "source": [
    "args = ObjectView({\n",
    "    'model_type': 'GraphSage',\n",
    "    'dataset': 'cora',\n",
    "    'num_layers': 2,\n",
    "    'heads': 1,\n",
    "    'batch_size': 32,\n",
    "    'hidden_dim': 32,\n",
    "    'dropout': 0.3,\n",
    "    'epochs': 500,\n",
    "    'opt': 'adam',\n",
    "    'opt_scheduler': None,\n",
    "    'opt_restart': 0,\n",
    "    'weight_decay': 5e-3,\n",
    "    'lr': 0.01\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-hobby",
   "metadata": {
    "id": "novel-hobby"
   },
   "source": [
    "Настройте аргументы и запустите функции train и test на разных блоках (*GraphSAGE* с семинара, *GCN*, *GAT*) на датасете Cora и на любом другом на выбор из доступных в библиотеке torch_geometric и сравните полученное качество на разных слоях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-measure",
   "metadata": {
    "id": "regulation-measure"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "charitable-ranch",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T21:08:21.821439Z",
     "start_time": "2022-11-02T21:08:21.816723Z"
    },
    "id": "charitable-ranch"
   },
   "source": [
    "Также поэксперементируйте с параметрами сетей и на основе экспериментов ниже напишите выводы. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-drunk",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T20:55:14.854665Z",
     "start_time": "2022-11-02T20:55:14.816633Z"
    },
    "id": "suited-drunk"
   },
   "source": [
    "__Отчет по экспериментам:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-damage",
   "metadata": {
    "id": "vietnamese-damage"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "useful-scoop",
   "metadata": {
    "id": "useful-scoop"
   },
   "source": [
    "### Бонус (1 балл)\n",
    "* Прикрепить ссылку на отчет по экспериментам из wandb (1 балл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-restaurant",
   "metadata": {
    "id": "advisory-restaurant"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "m1Max",
   "language": "python",
   "name": "m1max"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
