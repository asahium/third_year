{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85426f5a",
   "metadata": {
    "id": "85426f5a"
   },
   "source": [
    "# Домашнее задание 4\n",
    "\n",
    "## Глубинное обучение в анализе графовых данных, ПМИ ВШЭ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d0553e",
   "metadata": {
    "id": "41d0553e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.1.2+cu121.html\n",
      "Collecting torch-scatter\n",
      "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m593.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: torch-scatter\n",
      "  Building wheel for torch-scatter (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[46 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/__init__.py -> build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/placeholder.py -> build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/scatter.py -> build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/segment_coo.py -> build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/segment_csr.py -> build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/testing.py -> build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/utils.py -> build/lib.linux-x86_64-cpython-311/torch_scatter\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/__init__.py -> build/lib.linux-x86_64-cpython-311/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/logsumexp.py -> build/lib.linux-x86_64-cpython-311/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/softmax.py -> build/lib.linux-x86_64-cpython-311/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/std.py -> build/lib.linux-x86_64-cpython-311/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing torch_scatter.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to torch_scatter.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to torch_scatter.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to torch_scatter.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'torch_scatter._scatter_cpu' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311/csrc\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311/csrc/cpu\n",
      "  \u001b[31m   \u001b[0m gcc -Wsign-compare -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -fcf-protection -fexceptions -fcf-protection -fexceptions -fcf-protection -fexceptions -fPIC -DWITH_PYTHON -Icsrc -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/TH -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/THC -I/usr/include/python3.11 -c csrc/cpu/scatter_cpu.cpp -o build/temp.linux-x86_64-cpython-311/csrc/cpu/scatter_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_scatter_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m In file included from /home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/Device.h:4,\n",
      "  \u001b[31m   \u001b[0m                  from /home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/python.h:8,\n",
      "  \u001b[31m   \u001b[0m                  from /home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/extension.h:9,\n",
      "  \u001b[31m   \u001b[0m                  from /home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:6,\n",
      "  \u001b[31m   \u001b[0m                  from csrc/cpu/../extensions.h:2,\n",
      "  \u001b[31m   \u001b[0m                  from csrc/cpu/scatter_cpu.h:3,\n",
      "  \u001b[31m   \u001b[0m                  from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m /home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/python_headers.h:12:10: fatal error: Python.h: No such file or directory\n",
      "  \u001b[31m   \u001b[0m    12 | #include <Python.h>\n",
      "  \u001b[31m   \u001b[0m       |          ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m error: command '/bin/gcc' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for torch-scatter\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for torch-scatter\n",
      "Failed to build torch-scatter\n",
      "\u001b[31mERROR: Could not build wheels for torch-scatter, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.1.2+cu121.html\n",
      "Collecting torch-sparse\n",
      "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m840.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib64/python3.11/site-packages (from torch-sparse) (1.10.0)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib64/python3.11/site-packages (from scipy->torch-sparse) (1.24.1)\n",
      "Building wheels for collected packages: torch-sparse\n",
      "  Building wheel for torch-sparse (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[147 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/__init__.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/add.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/bandwidth.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/cat.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/coalesce.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/convert.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/diag.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/eye.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/index_select.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/masked_select.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/matmul.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/metis.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/mul.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/narrow.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/permute.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/reduce.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/rw.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/saint.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/sample.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/select.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spadd.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spmm.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spspmm.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/storage.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/tensor.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/testing.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/transpose.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/typing.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/utils.py -> build/lib.linux-x86_64-cpython-311/torch_sparse\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing torch_sparse.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to torch_sparse.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to torch_sparse.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to torch_sparse.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/css'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/html'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/tests'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/examples'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/benchmark'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'benchmark'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'torch_sparse._convert_cpu' extension\n",
      "  \u001b[31m   \u001b[0m creating /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/build/temp.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/build/temp.linux-x86_64-cpython-311/csrc\n",
      "  \u001b[31m   \u001b[0m creating /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/build/temp.linux-x86_64-cpython-311/csrc/cpu\n",
      "  \u001b[31m   \u001b[0m Emitting ninja build file /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/build/temp.linux-x86_64-cpython-311/build.ninja...\n",
      "  \u001b[31m   \u001b[0m Compiling objects...\n",
      "  \u001b[31m   \u001b[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  \u001b[31m   \u001b[0m [1/2] c++ -MMD -MF /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/build/temp.linux-x86_64-cpython-311/csrc/convert.o.d -Wsign-compare -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -fcf-protection -fexceptions -fcf-protection -fexceptions -fcf-protection -fexceptions -fPIC -DWITH_PYTHON -Icsrc -I/tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/third_party/parallel-hashmap -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/TH -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/THC -I/usr/include/python3.11 -c -c /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/csrc/convert.cpp -o /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/build/temp.linux-x86_64-cpython-311/csrc/convert.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_convert_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m \u001b[31mFAILED: \u001b[0m/tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/build/temp.linux-x86_64-cpython-311/csrc/convert.o\n",
      "  \u001b[31m   \u001b[0m c++ -MMD -MF /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/build/temp.linux-x86_64-cpython-311/csrc/convert.o.d -Wsign-compare -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -fcf-protection -fexceptions -fcf-protection -fexceptions -fcf-protection -fexceptions -fPIC -DWITH_PYTHON -Icsrc -I/tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/third_party/parallel-hashmap -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/TH -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/THC -I/usr/include/python3.11 -c -c /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/csrc/convert.cpp -o /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/build/temp.linux-x86_64-cpython-311/csrc/convert.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_convert_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/csrc/convert.cpp:2:10: fatal error: Python.h: No such file or directory\n",
      "  \u001b[31m   \u001b[0m     2 | #include <Python.h>\n",
      "  \u001b[31m   \u001b[0m       |          ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m [2/2] c++ -MMD -MF /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/build/temp.linux-x86_64-cpython-311/csrc/cpu/convert_cpu.o.d -Wsign-compare -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -fcf-protection -fexceptions -fcf-protection -fexceptions -fcf-protection -fexceptions -fPIC -DWITH_PYTHON -Icsrc -I/tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/third_party/parallel-hashmap -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/TH -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/THC -I/usr/include/python3.11 -c -c /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/csrc/cpu/convert_cpu.cpp -o /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/build/temp.linux-x86_64-cpython-311/csrc/cpu/convert_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_convert_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m \u001b[31mFAILED: \u001b[0m/tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/build/temp.linux-x86_64-cpython-311/csrc/cpu/convert_cpu.o\n",
      "  \u001b[31m   \u001b[0m c++ -MMD -MF /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/build/temp.linux-x86_64-cpython-311/csrc/cpu/convert_cpu.o.d -Wsign-compare -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -fcf-protection -fexceptions -fcf-protection -fexceptions -fcf-protection -fexceptions -fPIC -DWITH_PYTHON -Icsrc -I/tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/third_party/parallel-hashmap -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/TH -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/THC -I/usr/include/python3.11 -c -c /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/csrc/cpu/convert_cpu.cpp -o /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/build/temp.linux-x86_64-cpython-311/csrc/cpu/convert_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_convert_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m In file included from /home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/Device.h:4,\n",
      "  \u001b[31m   \u001b[0m                  from /home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/python.h:8,\n",
      "  \u001b[31m   \u001b[0m                  from /home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/extension.h:9,\n",
      "  \u001b[31m   \u001b[0m                  from /home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:6,\n",
      "  \u001b[31m   \u001b[0m                  from /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/csrc/cpu/../extensions.h:2,\n",
      "  \u001b[31m   \u001b[0m                  from /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/csrc/cpu/convert_cpu.h:3,\n",
      "  \u001b[31m   \u001b[0m                  from /tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/csrc/cpu/convert_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m /home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/python_headers.h:12:10: fatal error: Python.h: No such file or directory\n",
      "  \u001b[31m   \u001b[0m    12 | #include <Python.h>\n",
      "  \u001b[31m   \u001b[0m       |          ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m ninja: build stopped: subcommand failed.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 2100, in _run_ninja_build\n",
      "  \u001b[31m   \u001b[0m     subprocess.run(\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib64/python3.11/subprocess.py\", line 571, in run\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, process.args,\n",
      "  \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-p_dulm__/torch-sparse_40b389685c804c30ac61df9d1dcff14f/setup.py\", line 147, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/__init__.py\", line 103, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/dist.py\", line 963, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/wheel/bdist_wheel.py\", line 369, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"build\")\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/dist.py\", line 963, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/command/build.py\", line 131, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/dist.py\", line 963, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/command/build_ext.py\", line 88, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 345, in run\n",
      "  \u001b[31m   \u001b[0m     self.build_extensions()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 873, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     build_ext.build_extensions(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 467, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     self._build_extensions_serial()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 493, in _build_extensions_serial\n",
      "  \u001b[31m   \u001b[0m     self.build_extension(ext)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/command/build_ext.py\", line 249, in build_extension\n",
      "  \u001b[31m   \u001b[0m     _build_ext.build_extension(self, ext)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 548, in build_extension\n",
      "  \u001b[31m   \u001b[0m     objects = self.compiler.compile(\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 686, in unix_wrap_ninja_compile\n",
      "  \u001b[31m   \u001b[0m     _write_ninja_file_and_compile_objects(\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1774, in _write_ninja_file_and_compile_objects\n",
      "  \u001b[31m   \u001b[0m     _run_ninja_build(\n",
      "  \u001b[31m   \u001b[0m   File \"/home/wyrm/.local/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 2116, in _run_ninja_build\n",
      "  \u001b[31m   \u001b[0m     raise RuntimeError(message) from e\n",
      "  \u001b[31m   \u001b[0m RuntimeError: Error compiling objects for extension\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for torch-sparse\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for torch-sparse\n",
      "Failed to build torch-sparse\n",
      "\u001b[31mERROR: Could not build wheels for torch-sparse, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.1.2+cu121.html\n",
      "Collecting torch-cluster\n",
      "  Downloading torch_cluster-1.6.3.tar.gz (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m320.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib64/python3.11/site-packages (from torch-cluster) (1.10.0)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib64/python3.11/site-packages (from scipy->torch-cluster) (1.24.1)\n",
      "Building wheels for collected packages: torch-cluster\n",
      "  Building wheel for torch-cluster (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[45 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/torch_cluster\n",
      "  \u001b[31m   \u001b[0m copying torch_cluster/__init__.py -> build/lib.linux-x86_64-cpython-311/torch_cluster\n",
      "  \u001b[31m   \u001b[0m copying torch_cluster/fps.py -> build/lib.linux-x86_64-cpython-311/torch_cluster\n",
      "  \u001b[31m   \u001b[0m copying torch_cluster/graclus.py -> build/lib.linux-x86_64-cpython-311/torch_cluster\n",
      "  \u001b[31m   \u001b[0m copying torch_cluster/grid.py -> build/lib.linux-x86_64-cpython-311/torch_cluster\n",
      "  \u001b[31m   \u001b[0m copying torch_cluster/knn.py -> build/lib.linux-x86_64-cpython-311/torch_cluster\n",
      "  \u001b[31m   \u001b[0m copying torch_cluster/nearest.py -> build/lib.linux-x86_64-cpython-311/torch_cluster\n",
      "  \u001b[31m   \u001b[0m copying torch_cluster/radius.py -> build/lib.linux-x86_64-cpython-311/torch_cluster\n",
      "  \u001b[31m   \u001b[0m copying torch_cluster/rw.py -> build/lib.linux-x86_64-cpython-311/torch_cluster\n",
      "  \u001b[31m   \u001b[0m copying torch_cluster/sampler.py -> build/lib.linux-x86_64-cpython-311/torch_cluster\n",
      "  \u001b[31m   \u001b[0m copying torch_cluster/testing.py -> build/lib.linux-x86_64-cpython-311/torch_cluster\n",
      "  \u001b[31m   \u001b[0m copying torch_cluster/typing.py -> build/lib.linux-x86_64-cpython-311/torch_cluster\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing torch_cluster.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to torch_cluster.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to torch_cluster.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to torch_cluster.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'torch_cluster.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'torch_cluster.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'torch_cluster._fps_cpu' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311/csrc\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311/csrc/cpu\n",
      "  \u001b[31m   \u001b[0m gcc -Wsign-compare -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -fcf-protection -fexceptions -fcf-protection -fexceptions -fcf-protection -fexceptions -fPIC -DWITH_PYTHON -Icsrc -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/TH -I/home/wyrm/.local/lib/python3.11/site-packages/torch/include/THC -I/usr/include/python3.11 -c csrc/cpu/fps_cpu.cpp -o build/temp.linux-x86_64-cpython-311/csrc/cpu/fps_cpu.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_fps_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m In file included from /home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/Device.h:4,\n",
      "  \u001b[31m   \u001b[0m                  from /home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/python.h:8,\n",
      "  \u001b[31m   \u001b[0m                  from /home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/extension.h:9,\n",
      "  \u001b[31m   \u001b[0m                  from /home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:6,\n",
      "  \u001b[31m   \u001b[0m                  from csrc/cpu/../extensions.h:2,\n",
      "  \u001b[31m   \u001b[0m                  from csrc/cpu/fps_cpu.h:3,\n",
      "  \u001b[31m   \u001b[0m                  from csrc/cpu/fps_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m /home/wyrm/.local/lib/python3.11/site-packages/torch/include/torch/csrc/python_headers.h:12:10: fatal error: Python.h: No such file or directory\n",
      "  \u001b[31m   \u001b[0m    12 | #include <Python.h>\n",
      "  \u001b[31m   \u001b[0m       |          ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m error: command '/bin/gcc' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for torch-cluster\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for torch-cluster\n",
      "Failed to build torch-cluster\n",
      "\u001b[31mERROR: Could not build wheels for torch-cluster, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
      "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-7zc5q6up\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-7zc5q6up\n",
      "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 99717f69e7d251ea90d8416830cb6bac744e79b6\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from torch_geometric==2.4.0) (4.64.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib64/python3.11/site-packages (from torch_geometric==2.4.0) (1.24.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib64/python3.11/site-packages (from torch_geometric==2.4.0) (1.10.0)\n",
      "Requirement already satisfied: fsspec in /home/wyrm/.local/lib/python3.11/site-packages (from torch_geometric==2.4.0) (2023.12.2)\n",
      "Requirement already satisfied: jinja2 in /home/wyrm/.local/lib/python3.11/site-packages (from torch_geometric==2.4.0) (3.1.2)\n",
      "Collecting aiohttp (from torch_geometric==2.4.0)\n",
      "  Downloading aiohttp-3.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from torch_geometric==2.4.0) (2.25.1)\n",
      "Requirement already satisfied: pyparsing in /home/wyrm/.local/lib/python3.11/site-packages (from torch_geometric==2.4.0) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib64/python3.11/site-packages (from torch_geometric==2.4.0) (1.2.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/wyrm/.local/lib/python3.11/site-packages (from torch_geometric==2.4.0) (5.9.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->torch_geometric==2.4.0) (22.2.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch_geometric==2.4.0)\n",
      "  Downloading multidict-6.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m396.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp->torch_geometric==2.4.0)\n",
      "  Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric==2.4.0)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->torch_geometric==2.4.0)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/wyrm/.local/lib/python3.11/site-packages (from jinja2->torch_geometric==2.4.0) (2.1.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.11/site-packages (from requests->torch_geometric==2.4.0) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->torch_geometric==2.4.0) (2.10)\n",
      "Collecting urllib3<1.27,>=1.21.1 (from requests->torch_geometric==2.4.0)\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->torch_geometric==2.4.0) (2022.12.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/site-packages (from scikit-learn->torch_geometric==2.4.0) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn->torch_geometric==2.4.0) (3.1.0)\n",
      "Downloading aiohttp-3.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.1/328.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: torch_geometric\n",
      "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch_geometric: filename=torch_geometric-2.4.0-py3-none-any.whl size=1086100 sha256=7008bc48ea94e31eccaee88fde89d1a04fedf4553afa6be22fd32eb2cc671cdf\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-r7ktyres/wheels/93/bb/85/bfec4ee59b2563f74ec87cc2c91c6a4d3e40d3dcdec8ee5afe\n",
      "Successfully built torch_geometric\n",
      "Installing collected packages: urllib3, multidict, frozenlist, yarl, aiosignal, aiohttp, torch_geometric\n",
      "Successfully installed aiohttp-3.9.1 aiosignal-1.3.1 frozenlist-1.4.1 multidict-6.0.4 torch_geometric-2.4.0 urllib3-1.26.18 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35463c99",
   "metadata": {
    "id": "35463c99"
   },
   "source": [
    "## 1. Реализация TransE (10 баллов)\n",
    "\n",
    "В этом задании требуется реализовать пайплайн обучения эмбдеддингов графа знаний с помощью [TransE](https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf) для задачи прогнозирования отсутствующих ребер на наборе данных [Freebase](https://paperswithcode.com/dataset/fb15k) (FB15k-237), а также реализовать саму модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a2166d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T16:38:28.749186Z",
     "start_time": "2022-11-28T16:38:28.620681Z"
    },
    "id": "c5a2166d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/MichSchli/RelationPrediction/master/data/FB-Toutanova/entities.dict\n",
      "Downloading https://raw.githubusercontent.com/MichSchli/RelationPrediction/master/data/FB-Toutanova/relations.dict\n",
      "Downloading https://raw.githubusercontent.com/MichSchli/RelationPrediction/master/data/FB-Toutanova/test.txt\n",
      "Downloading https://raw.githubusercontent.com/MichSchli/RelationPrediction/master/data/FB-Toutanova/train.txt\n",
      "Downloading https://raw.githubusercontent.com/MichSchli/RelationPrediction/master/data/FB-Toutanova/valid.txt\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.datasets.rel_link_pred_dataset import RelLinkPredDataset\n",
    "\n",
    "\n",
    "dataset = RelLinkPredDataset('data', 'FB15k-237')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee68c8b9",
   "metadata": {
    "id": "ee68c8b9"
   },
   "source": [
    "#### TransE\n",
    "Ребра в графе знаний представляются тройками $(h, r, t)$. В TransE мы моделируем как объекты, так и отношения в пространстве эмбеддингов и пытаемся получить эмбеддинги, как $\\textbf h + \\textbf l \\approx \\textbf t$. Формально loss выглядит:\n",
    "\n",
    "$$\\sum_{((h, l, t), (h', l, t')) \\in T_{batch}} [\\gamma + d(\\textbf{h} + \\textbf{l}, \\textbf t) - d(\\textbf{h'} + \\textbf l, \\textbf{t'})]$$\n",
    "\n",
    "где $(h', l, t')$ представляет собой тройку, заменяя head или tail случайным объектом.\n",
    "$d(\\boldsymbol{h}+\\boldsymbol{l}, \\boldsymbol{t})$ – показатель _различия_ положительного ребра. Кроме того, $d\\left(\\boldsymbol{h}^{\\prime}+\\boldsymbol{l}, \\boldsymbol{t}^{\\prime}\\right)$ — это оценка _различия_ для отрицательной тройки, полученная изменением либо head, либо tail (но не оба) положительной тройки. Таким образом, TransE *предпочитает* более низкие оценки для положительных ребер и большие оценки для отрицательных ребер.\n",
    "\n",
    "Что касается параметра $\\gamma$, он используется для обеспечения того, чтобы оценка положительного ребра отличалась от оценки отрицательного ребра как минимум на $\\gamma$.\n",
    "\n",
    "Итого алгоритм TransE выглядит следующим образом:\n",
    "\n",
    "![](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-05-27_at_12.01.23_AM.png)\n",
    "\n",
    "Что касается реализации модели, можно инициализировать $\\textbf l$ и $\\textbf e$ в соответствии с приведенным выше псевдокодом. Чтобы вычислить $d(\\textbf{h} + \\textbf{l}, \\textbf t)$, нужно взять L2-норму $\\textbf h + \\textbf l - \\textbf t$.\n",
    "\n",
    "*Примечание: для повышения производительности можно нормализовать $\\textbf e$ каждую эпоху, а не каждый мини-батч.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdea747a",
   "metadata": {
    "id": "cdea747a"
   },
   "source": [
    "__Вспомогательные функции:__\n",
    "\n",
    "Одним из ключевых аспектов обучения модели является создание измененных троек путем замены head или tail случайным объектом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfe5efd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T15:59:33.777084Z",
     "start_time": "2022-11-28T15:59:33.771787Z"
    },
    "id": "ecfe5efd"
   },
   "outputs": [],
   "source": [
    "def create_neg_edge_index(edge_index, edge_type, num_entities):\n",
    "    head_or_tail = torch.randint(high=2, size=edge_type.size(),\n",
    "                                 device=device)\n",
    "    rand_entities = torch.randint(high=num_entities,\n",
    "                                  size=edge_type.size(), device=device)\n",
    "    # change when 1, otherwise regular head\n",
    "    heads = torch.where(head_or_tail == 1, rand_entities,\n",
    "                        edge_index[0, :])\n",
    "    # change when 0, otherwise regular tail\n",
    "    tails = torch.where(head_or_tail == 0, rand_entities,\n",
    "                        edge_index[1, :])\n",
    "    return torch.stack([heads, tails], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afac228",
   "metadata": {
    "id": "0afac228"
   },
   "source": [
    "Оценивать качество будем по Hits@10, Mean Rank и MRR (mean reciprocal rank).\n",
    "\n",
    "Hits@10 = $\\frac{|\\{r \\in P | r \\leq 10\\}|}{|P|}$, где $|P|$ — количество оценок, а $r$ — ранг.\n",
    "\n",
    "Mean Rank = $\\frac{1}{|P|}\\sum_{r \\in P}r$\n",
    "\n",
    "MMR = $\\frac{1}{|P|}\\sum_{r \\in P}\\frac{1}{r}$\n",
    "\n",
    "Подробнее о метриках можно узнать [здесь](https://arxiv.org/pdf/2002.06914.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e064eec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T15:59:34.258096Z",
     "start_time": "2022-11-28T15:59:34.249708Z"
    },
    "id": "2e064eec"
   },
   "outputs": [],
   "source": [
    "def mrr(predictions, gt):\n",
    "    indices = predictions.argsort()\n",
    "    return (1.0 / (indices == gt).nonzero()[:, 1].float().add(1.0)).sum().item()\n",
    "\n",
    "\n",
    "def mr(predictions, gt):\n",
    "    indices = predictions.argsort()\n",
    "    return ((indices == gt).nonzero()[:, 1].float().add(1.0)).sum().item()\n",
    "\n",
    "\n",
    "def hit_at_k(predictions, gt, device, k=10):\n",
    "    zero_tensor = torch.tensor([0], device=device)\n",
    "    one_tensor = torch.tensor([1], device=device)\n",
    "    _, indices = predictions.topk(k=k, largest=False)\n",
    "    return torch.where(indices == gt, one_tensor, zero_tensor).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2193ce2f",
   "metadata": {
    "id": "2193ce2f"
   },
   "source": [
    "__Требуется__ добиться качества хотя бы 0.17 MRR и 0.30 Hits@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a31ef0",
   "metadata": {
    "id": "c1a31ef0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dqZlPjwNyac_",
   "metadata": {
    "id": "dqZlPjwNyac_"
   },
   "source": [
    "### 1.1 Вопрос о нормализации (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_ZnyvNQdy-SH",
   "metadata": {
    "id": "_ZnyvNQdy-SH"
   },
   "source": [
    "Попробуйте обучить TransE без пятой строчки алгоритма (без нормализации по сущностям). Что происходит с обучением? Зачем требуется эта строка?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2767859c",
   "metadata": {
    "id": "2767859c"
   },
   "source": [
    "## 2. Нейросеть на гетерогенных данных (3 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LFkv3s8sykyG",
   "metadata": {
    "id": "LFkv3s8sykyG"
   },
   "source": [
    "Возьмите один из 2 датасетов (Freebase/ синтетический датасет hetero_graph далее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deGDhKWeCi3k",
   "metadata": {
    "id": "deGDhKWeCi3k"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "n_users = 1000\n",
    "n_items = 500\n",
    "n_follows = 3000\n",
    "n_clicks = 5000\n",
    "n_dislikes = 500\n",
    "n_hetero_features = 10\n",
    "n_user_classes = 5\n",
    "n_max_clicks = 10\n",
    "\n",
    "follow_src = np.random.randint(0, n_users, n_follows)\n",
    "follow_dst = np.random.randint(0, n_users, n_follows)\n",
    "click_src = np.random.randint(0, n_users, n_clicks)\n",
    "click_dst = np.random.randint(0, n_items, n_clicks)\n",
    "dislike_src = np.random.randint(0, n_users, n_dislikes)\n",
    "dislike_dst = np.random.randint(0, n_items, n_dislikes)\n",
    "\n",
    "hetero_graph = dgl.heterograph({\n",
    "    ('user', 'follow', 'user'): (follow_src, follow_dst),\n",
    "    ('user', 'followed-by', 'user'): (follow_dst, follow_src),\n",
    "    ('user', 'click', 'item'): (click_src, click_dst),\n",
    "    ('item', 'clicked-by', 'user'): (click_dst, click_src),\n",
    "    ('user', 'dislike', 'item'): (dislike_src, dislike_dst),\n",
    "    ('item', 'disliked-by', 'user'): (dislike_dst, dislike_src)})\n",
    "\n",
    "hetero_graph.nodes['user'].data['feature'] = torch.randn(n_users, n_hetero_features)\n",
    "hetero_graph.nodes['item'].data['feature'] = torch.randn(n_items, n_hetero_features)\n",
    "hetero_graph.nodes['user'].data['label'] = torch.randint(0, n_user_classes, (n_users,))\n",
    "hetero_graph.edges['click'].data['label'] = torch.randint(1, n_max_clicks, (n_clicks,)).float()\n",
    "# randomly generate training masks on user nodes and click edges\n",
    "hetero_graph.nodes['user'].data['train_mask'] = torch.zeros(n_users, dtype=torch.bool).bernoulli(0.6)\n",
    "hetero_graph.edges['click'].data['train_mask'] = torch.zeros(n_clicks, dtype=torch.bool).bernoulli(0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vOwWWxfCDPEK",
   "metadata": {
    "id": "vOwWWxfCDPEK"
   },
   "source": [
    "Используя любую библиотеку (torch geometry, dgl, stellargraph) соберите нейронную сеть и обучите ее (решать задачу Node Classification) на одном из двух датасетов выше.\n",
    "\n",
    "**БОНУСЫ:** \n",
    "(2 балла) Обучите нейросеть решать задачу link prediction\n",
    "\n",
    "(1 балл) возьмите еще какой-нибудь гетерогенный датасет (не маленький и не синтетический) и обучите на нем\n",
    "\n",
    "(4 балла) реализуйте самостоятельно Relational GCN и продемонстрируйте работоспобность вашего слоя. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T-QdveYJDaUY",
   "metadata": {
    "id": "T-QdveYJDaUY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
