{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGJ6ihQIAmxi"
      },
      "source": [
        "# ДЗ 4. Диффузия\n",
        "В этой домашке вам предстоит обучить DDPM на пресловутых лицах (CelebA 32х32). Решением является решенный ноутбук с обучением модели, сгенерированными картинками и, по требованию проверяющего, чекпоинтами"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zRmDKhrHXvP"
      },
      "source": [
        "# Imports and Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-utkUQOI1Z6"
      },
      "outputs": [],
      "source": [
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWj6n5ty9pNZ"
      },
      "outputs": [],
      "source": [
        "# # Для работы в колабе раскоменьте эти строки\n",
        "!git clone https://github.com/HSE-LAMBDA/DeepGenerativeModels.git\n",
        "%cd DeepGenerativeModels/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITxRF0yN_i-n"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4hfF9UGeANL"
      },
      "outputs": [],
      "source": [
        "import einops\n",
        "\n",
        "import random\n",
        "import imageio\n",
        "import numpy as np\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.transforms import Compose, ToTensor, Lambda, Resize\n",
        "from torchvision.datasets.mnist import MNIST, FashionMNIST\n",
        "from torchvision.datasets import CelebA # Можете использовать стандартный даталодер, если квота гдрайва позволяет\n",
        "# from utils.datasets.celeba import CelebADataset as CelebA\n",
        "\n",
        "\n",
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2DgEVAoEd1E"
      },
      "source": [
        "# Визуализация данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnQA-V2TEd6d"
      },
      "outputs": [],
      "source": [
        "def show_images(images, title=\"\"):\n",
        "    \"\"\"Shows the provided images as sub-pictures in a square\"\"\"\n",
        "\n",
        "    # Converting images to CPU numpy arrays\n",
        "    if type(images) is torch.Tensor:\n",
        "        images = images.detach().cpu().permute(0,2,3,1).numpy()\n",
        "\n",
        "    # Defining number of rows and columns\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    rows = int(len(images) ** (1 / 2))\n",
        "    cols = round(len(images) / rows)\n",
        "\n",
        "    # Populating figure with sub-plots\n",
        "    idx = 0\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            fig.add_subplot(rows, cols, idx + 1)\n",
        "\n",
        "            if idx < len(images):\n",
        "                plt.imshow((255*(images[idx]+1)/2).astype('uint8'))\n",
        "                idx += 1\n",
        "    fig.suptitle(title, fontsize=30)\n",
        "\n",
        "    # Showing the figure\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkWnTOS0EitS"
      },
      "outputs": [],
      "source": [
        "def show_first_batch(loader):\n",
        "    for batch in loader:\n",
        "        show_images(batch[0], \"Первый батч\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GxdeBS4HZq9"
      },
      "source": [
        "## Загрузка данных (0 баллов)\n",
        "\n",
        "Мы будем использовать CelebA (32x32). **Важно**: отнормируйте данные в интервал `[-1,1]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t20MwkvbB41G"
      },
      "outputs": [],
      "source": [
        "!cd /content/gdrive/MyDrive/celeba && unzip img_align_celeba.zip > /dev/null # распаковка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ5tnfbfeND8",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "batch_size = 128\n",
        "image_size = 32\n",
        "\n",
        "transform = Compose([\n",
        "    ToTensor(),\n",
        "    Lambda(lambda x: (x - 0.5) * 2)]\n",
        ")\n",
        "\n",
        "# transform = ??? # YOUR CODE HERE\n",
        "#dataset = CelebA(\"./datasets\", download=True, split='train', transform=transform)\n",
        "dataset = CelebA(\"/content/gdrive/MyDrive/celeba/\", download=False, split='train', transform=transform)\n",
        "loader = DataLoader(dataset, batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOFIp14opS4K"
      },
      "outputs": [],
      "source": [
        "show_first_batch(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXPKke_S76cb"
      },
      "outputs": [],
      "source": [
        "# Getting device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\\t\" + (f\"{torch.cuda.get_device_name(0)}\" if torch.cuda.is_available() else \"CPU\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY_qhk428P17"
      },
      "source": [
        "# Denoising Diffusion Model (DDPM) (2 балла)\n",
        "\n",
        "## Recap\n",
        "Диффузия - это обратимый стохастический процесс, в котором картинка зашумляется по известному гауссовскому закону $q(x_t|x_{t-1})$ и денойзится по неизвестному обратному гауссовскому закону $p(x_{t-1}|x_t)$, который приближается нейросетью $p_\\theta$\n",
        "![](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/DDPM.png)\n",
        "\n",
        "Известный закон $q$ (он же forward pass) описывается по формуле:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathbf{x}_t\n",
        "&= \\sqrt{\\alpha_t}\\mathbf{x}_{t-1} + \\sqrt{1 - \\alpha_t}\\boldsymbol{\\epsilon}_{t-1} & \\text{ ;where } \\boldsymbol{\\epsilon}_{t-1}, \\boldsymbol{\\epsilon}_{t-2}, \\dots \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}) \\\\\n",
        "&= \\sqrt{\\alpha_t \\alpha_{t-1}} \\mathbf{x}_{t-2} + \\sqrt{1 - \\alpha_t \\alpha_{t-1}} \\bar{\\boldsymbol{\\epsilon}}_{t-2} & \\text{ ;where } \\bar{\\boldsymbol{\\epsilon}}_{t-2} \\text{ merges two Gaussians (*).} \\\\\n",
        "&= \\dots \\\\\n",
        "&= \\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\boldsymbol{\\epsilon} \\\\\n",
        "q(\\mathbf{x}_t \\vert \\mathbf{x}_0) &= \\mathcal{N}(\\mathbf{x}_t; \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0, (1 - \\bar{\\alpha}_t)\\mathbf{I})\n",
        "\\end{aligned}\n",
        "$$, где $\\alpha$ - заранее определенные по определенной сетке константы\n",
        "\n",
        "Неизвестная же гауссиана обратного закона (он же backward pass) предсказывается нейросетью:\n",
        "$p_\\theta(x_{t-1}|x_t) = \\mathcal{N}(x_{t-1};\\mu_\\theta(x_t, t),\\sigma_\\theta(x_t,t))$ (т.е. предсказываются $\\mu$ и $\\sigma$, 1в1 как в вариационном енкодере)\n",
        "\n",
        "Кроме этого, так же, как в варэнкодере, $p_\\theta$ выучивается максимизацией ELBO (и даже KL там тоже между двумя гауссианами)\n",
        "\n",
        "Ну а выучив обратный процесс денойзинга $p_\\theta(x_{t-1}|x_t)$, дело останется за малым: берём $x_T\\sim\\mathcal{N}(0,1)$ и семплируем $x_{t-1}\\sim p_\\theta(x_{t-1}|x_t)$, пока не восстановим наш незашумленный $x_0$. Это и будет какая-то картинка\n",
        "\n",
        "## DDPM\n",
        "\n",
        "С варвыводом вы уже хорошо знакомы, но авторы DDPM решили с ним не париться и забить на $\\sigma_t$, сделав её заранее определённой константой, например:\n",
        "- $\\sigma_t^2$ = $\\beta_t$\n",
        "- $\\sigma_t^2$ = $\\frac{1 - \\bar{\\alpha_{t-1}}}{1 - \\bar{\\alpha_{t}}} \\beta_t$\n",
        "\n",
        "Тогда\n",
        "$$q(x_{t-1}|x_0, x_t)=\\mathcal{N}(x_{t-1}|\\mu_t^q,\\sigma_t)$$\n",
        "$$p_\\theta(x_{t-1}|x_t)=\\mathcal{N}(x_{t-1}|\\mu_t^\\theta,\\sigma_t)$$\n",
        "\n",
        "Кроме этого, из вышеуказанного прямого закона $q$ несложно представить $\\mu_t^q$ в виде\n",
        "\n",
        "$$\\boldsymbol{\\mu}^q_t = \\frac{1}{\\sqrt{\\alpha_t}} \\Big( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\boldsymbol{\\epsilon}_t \\Big)$$\n",
        "\n",
        "Так давайте представим и $\\mu^\\theta_t$ в таком виде, раз так:\n",
        "$$\\boldsymbol{\\mu}^\\theta_t = \\frac{1}{\\sqrt{\\alpha_t}} \\Big( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\boldsymbol{\\epsilon}_t^\\theta(x_t,t) \\Big)$$\n",
        "\n",
        "Тогда весь $KL(q|p_\\theta)$ сведётся к минимизации MSE\n",
        "\n",
        "$$||\\mu_t^q-\\mu_t^\\theta||^2\\sim||\\epsilon_t-\\epsilon_t^\\theta(x_t,t)||^2$$\n",
        "\n",
        "Ну а зашумленный $x_t$ можно считать из исходного $x_0$ по быстрой формуле (см. самое начало):\n",
        "\n",
        "$$x_t=\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\boldsymbol{\\epsilon}_t$$\n",
        "\n",
        "$\\epsilon_t$ же на деле берут случайно из $\\mathcal{N}(0,1)$\n",
        "\n",
        "Итого, все-эти-ваши диффузии можно представить в виде нескольких строк кода:\n",
        "![](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/DDPM-algo.png)\n",
        "\n",
        "Прим. В качестве $\\epsilon^\\theta$ берут любой Unet-like бэкбон (кроме этого, есть оптимизированный под диффузию Efficient Unet)\n",
        "\n",
        "Для большей инфы по диффузии идите сюда https://lilianweng.github.io/posts/2021-07-11-diffusion-models/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Menl_lR8SCC"
      },
      "outputs": [],
      "source": [
        "# DDPM class\n",
        "class DDPM(nn.Module):\n",
        "    def __init__(self, network, # Unet\n",
        "                 n_steps=200, # YOUR CODE HERE (число шагов диффузии)\n",
        "                 min_beta=10 ** -4, # YOUR CODE HERE\n",
        "                 max_beta=0.02, # YOUR CODE HERE\n",
        "                 device=None,\n",
        "                 image_chw=(3, image_size, image_size)):\n",
        "        super().__init__()\n",
        "        self.n_steps = n_steps\n",
        "        self.device = device\n",
        "        self.image_chw = image_chw\n",
        "        self.network = network.to(device) # Ваш backbone (Unet), реализуете его ниже\n",
        "        self.betas = torch.linspace(min_beta, max_beta, n_steps).to(\n",
        "            device) # Задайте beta по любой понравившейся сетке, как на семинаре\n",
        "        self.alphas = 1 - self.betas\n",
        "        self.alpha_bars = torch.tensor([torch.prod(self.alphas[:i + 1]) for i in range(len(self.alphas))]).to(device)\n",
        "\n",
        "    def forward(self, x0, t, eta=None):\n",
        "        # Прямой проход диффузии (детерменированный марковский процесс)\n",
        "        # :param x0 - исходная картинка (тензор формы [B,C,H,W])\n",
        "        # :param t - шаг зашумления (тензор формы [B,1])\n",
        "        # :param eta - \\epsilon_t - добавочный шум на шаге зашумления t (тензор формы [B,C,H,W])\n",
        "        n, c, h, w = x0.shape\n",
        "        a_bar = self.alpha_bars[t]\n",
        "        # YOUR CODE HERE\n",
        "        if eta is None:\n",
        "            eta = torch.randn(n, c, h, w).to(self.device) # если шум не определен - инициализируйте его гауссом N(0,1) сами\n",
        "        noised_x = a_bar.sqrt().reshape(n, 1, 1, 1) * x0 + (1 - a_bar).sqrt().reshape(n, 1, 1, 1) * eta\n",
        "        return noised_x\n",
        "\n",
        "    def backward(self, x, t):\n",
        "        # Обратный процесс. Здесь вам предстоит восстановить добавочный шум eta из зашумлённой картинки x на шаге t нейросетью\n",
        "        eta_pred = self.network(x, t)\n",
        "        return eta_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbDZPtutErS8"
      },
      "source": [
        "## Visualizing forward and backward (2 балла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY416VfcErbO"
      },
      "outputs": [],
      "source": [
        "def show_forward(ddpm, loader, device):\n",
        "    for batch in loader:\n",
        "        imgs = batch[0]\n",
        "\n",
        "        show_images(imgs, \"Original images\")\n",
        "\n",
        "        for percent in [0.25, 0.5, 0.75, 1]: # Шаг зашумления (в процентах от максимального)\n",
        "            noised_images = [int(percent * ddpm.n_steps) - 1 for _ in range(len(imgs))] # YOUR CODE HERE. Зашумите ваши картинки прямым проходом DDPM\n",
        "            show_images(\n",
        "                noised_images,\n",
        "                f\"DDPM Noisy images {int(percent * 100)}%\"\n",
        "            )\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQGApj4_Ewmt"
      },
      "outputs": [],
      "source": [
        "def generate_new_images(ddpm, n_samples=16, device=None, frames_per_gif=100,\n",
        "                        gif_name=\"sampling.gif\", c=3, h=image_size, w=image_size):\n",
        "    \"\"\"Given a DDPM model, a number of samples to be generated and a device, returns some newly generated samples\"\"\"\n",
        "    frame_idxs = np.linspace(0, ddpm.n_steps, frames_per_gif).astype(np.uint)\n",
        "    frames = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if device is None:\n",
        "            device = ddpm.device\n",
        "\n",
        "        # Starting from random noise\n",
        "        x = torch.randn(n_samples, c, h, w).to(device) # Начинаем генерить картинки с гауссовского шума N(0,1) ([n_samples, c, h, w])\n",
        "\n",
        "        for idx, t in enumerate(list(range(ddpm.n_steps))[::-1]): # Денойзим наши картинки для каждого шага, начиная с последнего\n",
        "            # Estimating noise to be removed\n",
        "            time_tensor = (torch.ones(n_samples, 1) * t).to(device).long() # [n_samples, 1].long()\n",
        "            eta_theta = ddpm.backward(x, time_tensor) #  Предсказываем добавочный шум нейросетью\n",
        "\n",
        "            alpha_t = ddpm.alphas[t]\n",
        "            alpha_t_bar = ddpm.alpha_bars[t]\n",
        "\n",
        "            # Partially denoising the image\n",
        "            x = (1 / alpha_t.sqrt()) * (x - (1 - alpha_t) / (1 - alpha_t_bar).sqrt() * eta_theta) # Вычитаем добавочный шум из картинки\n",
        "\n",
        "            if t > 0:\n",
        "                z = torch.randn(n_samples, c, h, w).to(device)\n",
        "                beta_t = ddpm.betas[t]\n",
        "                sigma_t = beta_t.sqrt() # определите сигму по любому из предлагаемых DDPM способов\n",
        "\n",
        "                x = x + sigma_t * z\n",
        "\n",
        "            # Adding frames to the GIF\n",
        "            if idx in frame_idxs or t == 0:\n",
        "                normalized = x.clone()\n",
        "                for i in range(len(normalized)):\n",
        "                    normalized[i] -= torch.min(normalized[i])\n",
        "                    normalized[i] *= 255 / torch.max(normalized[i]) # YOUR CODE HERE (нормируем картинку обратно в интервал [0,255])\n",
        "\n",
        "                # Reshaping batch (n, c, h, w) to be a (as much as it gets) square frame\n",
        "                frame = einops.rearrange(normalized, \"(b1 b2) c h w -> (b1 h) (b2 w) c\", b1=int(n_samples ** 0.5))\n",
        "                frame = frame.cpu().numpy().astype(np.uint8)\n",
        "\n",
        "                # Rendering frame\n",
        "                frames.append(frame)\n",
        "\n",
        "    # Storing the gif\n",
        "    with imageio.get_writer(gif_name, mode=\"I\") as writer:\n",
        "        for idx, frame in enumerate(frames):\n",
        "            writer.append_data(frame)\n",
        "            if idx == len(frames) - 1:\n",
        "                for _ in range(frames_per_gif // 3):\n",
        "                    writer.append_data(frames[-1])\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GDfFXcGDe3D"
      },
      "source": [
        "# UNet backbone ($\\epsilon^\\theta$) (3 балла)\n",
        "\n",
        "Как уже было сказано, в качестве $\\epsilon^\\theta$ подойдёт любой Unet-like бэкбон (который будет принимать на вход зашумлённую картинку и на выходе возвращать восстановленный шум $\\epsilon_t$ той же размерности). Одна незадача - вторым аргументом $\\epsilon^\\theta$ принимает время (шаг зашумления) $t$, чего в ванильном Unet'e нет.\n",
        "\n",
        "К счастью, есть миллион и один способ добавить время дополнительным аргументом (например, AdaIN, как в StyleGAN, дополнительным каналом и т.д.)\n",
        "\n",
        "На практике же в DDPM делают positional encoding (тот самый, который в Трансформере) времени $t$ и дальше просто плюсуют его прямо к входной картинке $x$. Мало того, вместе в временем иногда ещё и какие-нибудь текстовые эмбединги приплюсовывают (сжимая их нехитрым образом до нужной размерности через дополнительный линейный слой)\n",
        "\n",
        "С текстовыми эмбедингами мы работать в этой домашке не будем, а вот $t$ добавлять будем ровно последним способом"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqvzCL5eDnSf"
      },
      "outputs": [],
      "source": [
        "def sinusoidal_embedding(n, d):\n",
        "    # n - размерность исходных данных (в нашем случае число моментов времени)\n",
        "    # d - выходная размерность\n",
        "    embedding = torch.zeros(n, d)\n",
        "    wk = torch.tensor([1 / 10_000 ** (2 * j / d) for j in range(d)]) # коэффициенты для d гармоник\n",
        "    wk = wk.reshape((1, d))\n",
        "    t = torch.arange(n).reshape((n, 1))\n",
        "    embedding[:,::2] = torch.sin(t * wk[:,::2])\n",
        "    embedding[:,1::2] = torch.cos(t * wk[:,::2]) # заполните половину из d компонент синунами sin(wk*t), оставшуюся косинусами cos(wk*t), где wk - коэффициенты гармоник\n",
        "    return embedding\n",
        "\n",
        "class MyBlock(nn.Module):\n",
        "    def __init__(self, shape, in_c, out_c, kernel_size=3, stride=1, padding=1, activation=None, normalize=True):\n",
        "        super(MyBlock, self).__init__()\n",
        "        self.ln = nn.LayerNorm(shape)\n",
        "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size, stride, padding)\n",
        "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size, stride, padding)\n",
        "        self.activation = nn.SiLU() if activation is None else activation\n",
        "        self.normalize = normalize\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.ln(x) if self.normalize else x\n",
        "        out = self.conv1(out)\n",
        "        out = self.activation(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.activation(out)\n",
        "        return out\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_steps=1000, time_emb_dim=100):\n",
        "        super().__init__()\n",
        "\n",
        "        # Sinusoidal embedding\n",
        "        self.time_embed = nn.Embedding(n_steps, time_emb_dim)\n",
        "        self.time_embed.weight.data = sinusoidal_embedding(n_steps, time_emb_dim)\n",
        "        self.time_embed.requires_grad_(False) # мы эмбединг слой уже инициализировали и менять его не будем\n",
        "\n",
        "        self.te1 = self._make_te(time_emb_dim, 1)\n",
        "        self.b1 = nn.Sequential(\n",
        "            MyBlock((1, 28, 28), 1, 10),\n",
        "            MyBlock((10, 28, 28), 10, 10),\n",
        "            MyBlock((10, 28, 28), 10, 10)\n",
        "        )\n",
        "        self.down1 = nn.Conv2d(10, 10, 4, 2, 1)\n",
        "\n",
        "        self.te2 = self._make_te(time_emb_dim, 10)\n",
        "        self.b2 = nn.Sequential(\n",
        "            MyBlock((10, 14, 14), 10, 20),\n",
        "            MyBlock((20, 14, 14), 20, 20),\n",
        "            MyBlock((20, 14, 14), 20, 20)\n",
        "        )\n",
        "        self.down2 = nn.Conv2d(20, 20, 4, 2, 1)\n",
        "\n",
        "        self.te3 = self._make_te(time_emb_dim, 20)\n",
        "        self.b3 = nn.Sequential(\n",
        "            MyBlock((20, 7, 7), 20, 40),\n",
        "            MyBlock((40, 7, 7), 40, 40),\n",
        "            MyBlock((40, 7, 7), 40, 40)\n",
        "        )\n",
        "        self.down3 = nn.Sequential(\n",
        "            nn.Conv2d(40, 40, 2, 1),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(40, 40, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.te_mid = self._make_te(time_emb_dim, 40)\n",
        "        self.b_mid = nn.Sequential(\n",
        "            MyBlock((40, 3, 3), 40, 20),\n",
        "            MyBlock((20, 3, 3), 20, 20),\n",
        "            MyBlock((20, 3, 3), 20, 40)\n",
        "        )\n",
        "\n",
        "        self.up1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(40, 40, 4, 2, 1),\n",
        "            nn.SiLU(),\n",
        "            nn.ConvTranspose2d(40, 40, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.te4 = self._make_te(time_emb_dim, 80)\n",
        "        self.b4 = nn.Sequential(\n",
        "            MyBlock((80, 7, 7), 80, 40),\n",
        "            MyBlock((40, 7, 7), 40, 20),\n",
        "            MyBlock((20, 7, 7), 20, 20)\n",
        "        )\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(20, 20, 4, 2, 1)\n",
        "        self.te5 = self._make_te(time_emb_dim, 40)\n",
        "        self.b5 = nn.Sequential(\n",
        "            MyBlock((40, 14, 14), 40, 20),\n",
        "            MyBlock((20, 14, 14), 20, 10),\n",
        "            MyBlock((10, 14, 14), 10, 10)\n",
        "        )\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(10, 10, 4, 2, 1)\n",
        "        self.te_out = self._make_te(time_emb_dim, 20)\n",
        "        self.b_out = nn.Sequential(\n",
        "            MyBlock((20, 28, 28), 20, 10),\n",
        "            MyBlock((10, 28, 28), 10, 10),\n",
        "            MyBlock((10, 28, 28), 10, 10, normalize=False)\n",
        "        )\n",
        "\n",
        "        self.conv_out = nn.Conv2d(10, 1, 3, 1, 1)\n",
        "\n",
        "    def _make_te(self, dim_in, dim_out):\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(dim_in, dim_out),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(dim_out, dim_out)\n",
        "        )\n",
        "    def forward(self, x, t):\n",
        "        t = self.time_embed(t)\n",
        "        n = len(x)\n",
        "        x = x + self.te1(t).reshape(n, -1, 1, 1)\n",
        "\n",
        "        out1 = self.b1(x + self.te1(t).reshape(n, -1, 1, 1))\n",
        "        out2 = self.b2(self.down1(out1) + self.te2(t).reshape(n, -1, 1, 1))\n",
        "        out3 = self.b3(self.down2(out2) + self.te3(t).reshape(n, -1, 1, 1))\n",
        "\n",
        "        out_mid = self.b_mid(self.down3(out3) + self.te_mid(t).reshape(n, -1, 1, 1))\n",
        "\n",
        "        out4 = torch.cat((out3, self.up1(out_mid)), dim=1)\n",
        "        out4 = self.b4(out4 + self.te4(t).reshape(n, -1, 1, 1))\n",
        "\n",
        "        out5 = torch.cat((out2, self.up2(out4)), dim=1)\n",
        "        out5 = self.b5(out5 + self.te5(t).reshape(n, -1, 1, 1))\n",
        "\n",
        "        out = torch.cat((out1, self.up3(out5)), dim=1)\n",
        "        out = self.b_out(out + self.te_out(t).reshape(n, -1, 1, 1))\n",
        "\n",
        "        out = self.conv_out(out)\n",
        "\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8YotKGi8dYW"
      },
      "outputs": [],
      "source": [
        "# Defining model\n",
        "n_steps, min_beta, max_beta = 1000, 10 ** -4, 0.02\n",
        "ddpm = DDPM(UNet(n_steps), n_steps=n_steps, min_beta=min_beta, max_beta=max_beta, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBUbjFMarUFC"
      },
      "outputs": [],
      "source": [
        "sum([p.numel() for p in ddpm.parameters()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHUEtZlP8is6"
      },
      "source": [
        "# Optional visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a5kTn5N8p9r"
      },
      "outputs": [],
      "source": [
        "# Optionally, load a pre-trained model that will be further trained\n",
        "# ddpm.load_state_dict(torch.load(store_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1pmuQQP8ixp"
      },
      "outputs": [],
      "source": [
        "# Optionally, show the diffusion (forward) process\n",
        "show_forward(ddpm, loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PV6tXQy_8uf1"
      },
      "outputs": [],
      "source": [
        "# Optionally, show the denoising (backward) process\n",
        "generated = generate_new_images(ddpm, gif_name=\"before_training.gif\")\n",
        "show_images(generated, \"Images generated before training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjgbi0iRDvH_"
      },
      "source": [
        "# Обучение (1 балл)\n",
        "![](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/DDPM-algo.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJcKvYEZDvaa"
      },
      "outputs": [],
      "source": [
        "def training_loop(ddpm, loader, n_epochs, optim, device, display=False, store_path=\"ddpm_model.pt\"):\n",
        "    mse = nn.MSELoss()\n",
        "    best_loss = float(\"inf\")\n",
        "    n_steps = ddpm.n_steps\n",
        "\n",
        "    for epoch in tqdm(range(n_epochs), desc=f\"Training progress\", colour=\"#00ff00\"):\n",
        "        epoch_loss = 0.0\n",
        "        for step, batch in enumerate(tqdm(loader, leave=False, desc=f\"Epoch {epoch + 1}/{n_epochs}\", colour=\"#005500\")):\n",
        "            x0 = batch[0].to(device)\n",
        "\n",
        "            eta = torch.randn_like(x0).to(device)\n",
        "            t = torch.randint(0, n_steps, (n,)).to(device)\n",
        "\n",
        "            noisy_imgs = ddpm(x0, t, eta) # получаем зашумленное изображение для шага t\n",
        "\n",
        "            # Getting model estimation of noise based on the images and the time-step\n",
        "            eta_theta = ddpm.backward(noisy_imgs, t.reshape(n, -1)) # восстанавливаем добавочный шум\n",
        "\n",
        "            loss = mse(eta_theta, eta) # учимся его восстанавливать нейросетью\n",
        "            optim.zero_grad()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            epoch_loss += loss.item() * len(x0) / len(loader.dataset)\n",
        "\n",
        "        # Display images generated at this epoch\n",
        "        if display:\n",
        "            show_images(generate_new_images(ddpm, device=device), f\"Images generated at epoch {epoch + 1}\")\n",
        "\n",
        "        log_string = f\"Loss at epoch {epoch + 1}: {epoch_loss:.3f}\"\n",
        "\n",
        "        # Storing the model\n",
        "        if best_loss > epoch_loss:\n",
        "            best_loss = epoch_loss\n",
        "            torch.save(ddpm.state_dict(), store_path)\n",
        "            log_string += \" --> Best model ever (stored)\"\n",
        "\n",
        "        print(log_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1nBeISig2AE"
      },
      "outputs": [],
      "source": [
        "store_path = \"/content/gdrive/MyDrive/checkpoints/celeba_ddpm.ckpt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRTedmnAD24Z"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "n_epochs = 200\n",
        "lr = 10 ** -4\n",
        "if not os.path.isdir(os.path.dirname(store_path)): os.mkdir(os.path.dirname(store_path))\n",
        "training_loop(ddpm, loader, n_epochs, optim=Adam(ddpm.parameters(), lr), device=device, store_path=store_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kdY0ZUuD50F"
      },
      "source": [
        "# Генерёжка (2 балла за хорошие картинки)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wGnH4g6D58A"
      },
      "outputs": [],
      "source": [
        "# Loading the trained model\n",
        "best_model = DDPM(UNet(), n_steps=n_steps, device=device)\n",
        "best_model.load_state_dict(torch.load(store_path, map_location=device))\n",
        "best_model.eval()\n",
        "print(\"Model loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r_67l-DEL7y"
      },
      "outputs": [],
      "source": [
        "print(\"Generating new images\")\n",
        "generated = generate_new_images(\n",
        "        best_model,\n",
        "        n_samples=100,\n",
        "        device=device,\n",
        "        gif_name=\"celeba.gif\"\n",
        "    )\n",
        "show_images(generated, \"Final result\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMqv53xOJEyF"
      },
      "source": [
        "# Visualizing the diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnd5RGOyJFKo"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(open('celeba.gif','rb').read())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}